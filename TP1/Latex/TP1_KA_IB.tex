\documentclass[10pt,a4paper]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
\usepackage{microtype}
\UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            bookmarks=true,
            pdfauthor={},
            pdftitle={titre non affiche},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=magenta,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls
\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\setcounter{secnumdepth}{5}

\providecommand{\tightlist}{%
  %\setlength{\itemsep}{0pt}
  \setlength{\parskip}{0pt}
  }

%%% Use protect on footnotes to avoid problems with footnotes in titles
\let\rmarkdownfootnote\footnote%
\def\footnote{\protect\rmarkdownfootnote}


  \title{titre non affiche}
    \author{}
    \date{}
  
% Packages

\usepackage[utf8]{inputenc}
\usepackage{setspace}
%\usepackage[french]{babel} % Pour la traduction française
%\renewcommand\frenchtablename{\textsc{Tableau}} %renommer table en tableau
%\AtBeginDocument{\renewcommand{\abstractname}{Synthèse}} %titre abstract
\usepackage{mathptmx} %times roman {mathptmx} OU {newtxtext} 
\DeclareSymbolFont{calletters}{OMS}{cmsy}{m}{n}  %pour differencier mathcal et mathscr
\DeclareSymbolFontAlphabet{\mathcal}{calletters} %pour differencier mathcal et mathscr
\usepackage[hmargin=1.5cm,vmargin=1.5cm]{geometry} % marges
\usepackage{caption}
\usepackage{graphicx}
\usepackage{natbib}
\usepackage[dvipsnames]{xcolor}
\usepackage{fontawesome5}
\DeclareMathOperator{\arctanh}{arctanh}
\usepackage{amsfonts}
\usepackage{dsfont}
\usepackage{xspace}
\usepackage{enumitem}
\usepackage{pifont}
\usepackage{wrapfig}
\usepackage{textpos}
\usepackage{array}
\usepackage{amsmath}
\usepackage{mathrsfs}  
\usepackage{tcolorbox}
\usepackage{here} %positionner les images
\usepackage{colortbl} %colorer un tableau


\usepackage{ntheorem}
\theoremstyle{break}
\newtheorem{theorem}{Théorème}[section]
\newtheorem{lemma}{Lemme}[section]
\newtheorem{proposition}{Propriété}[section]
\newtheorem{corollary}{Corollaire}[section]
\newenvironment{proof}{\textbf{Preuve}}{$\Box$}
\newtheorem{definition}{Définition}[section]
\newtheorem{example}{Exemple}[section]
\newtheorem{remark}{Remarque}[section]
\newtheorem{conjecture}{Hypothèse}[section]
\newtheorem{problem}{Problème}[section]
\newtheorem{algo}{Algorithme}[section]
\def\cP{{\mathcal{P}}} 
\def\cM{{\mathcal{M}}} 
\def\CC{{\mathcal{C}}} 
\def\NN{{\mathbb{N}}}
\def\RR{{\mathbb{RR}}}
\definecolor{rougeENSAE}{RGB}{188, 24, 39}

%\onehalfspacing 



% % Page de garde
% 
% \makeatletter
% \def\@maketitle{%
%   \clearpage
%  \thispagestyle{empty}
% 
% \begin{textblock*}{\textwidth}(-7cm,-3.5cm)
% \begin{center}
% \includegraphics[height=3cm]{img/900px-LOGO-ENSAE.png}
% \end{center}
% \end{textblock*}
% 
% \begin{minipage}{0.3\textwidth}
%   \begin{flushleft} \large
%     \textbf{ANTUNEZ Kim \vspace{8.75mm} }
%   \end{flushleft}
% \end{minipage}
% \begin{minipage}{0.6\textwidth}
%   \begin{flushright} 
%   \large{
%     \textbf{ENSAE 2\up{ème} année\\}
%   }     
%   \small
%     \textbf{ 
%         \textit{Stage d'application\\
%         Année scolaire 2019 - 2020}
%     }
%   \end{flushright}
% \end{minipage}
% 
% \vspace*{2cm}
% 
% \begin{center}
%     \fbox{\parbox{0.9\textwidth}{
%         \begin{huge}\begin{center}
%             \textbf{Échantillonnage spatial déterminantal}\\
%         \end{center}\end{huge}}}
% \end{center}
% 
% \vfill
% 
% \begin{center}
% \includegraphics[width=0.6\linewidth]{img/markdown-figPG-1}
% \end{center}
% 
% \vfill
%     
% \begin{minipage}{0.4\textwidth}
%     \begin{flushleft} \large 
%     \textbf{Direction générale de l'Insee\\
%         Montrouge, France
%     }
%   \end{flushleft}
% \end{minipage} 
% \begin{minipage}{0.6\textwidth}
%   \begin{flushright} \large
%     \textbf{
%         Maître de stage : Vincent \textsc{Loonis}\\
%         08/06/2020 - 14/08/2020
%     }
%   \end{flushright}
% \end{minipage}    
% 
% \vspace*{1cm}
% 
% 
% \textcolor{rougeENSAE}{\rule{10mm}{1.5mm}}
% 
% \scriptsize
% \textbf{ENSAE Paris}\newline TSA 26644
% \rightline{\href{www.ensae.fr}{\textcolor{rougeENSAE}{\textbf{www.ensae.fr}}}$\quad \qquad \qquad$}
% Service des relations entreprises et des stages\newline
% 5, avenue Henry Le Chatelier -- 91764 PALAISEAU CEDEX -- FRANCE -- Tél : +33 (0)1 70 26 67 39 -- Courriel : stage\symbol{64}ensae.fr
% 
% \normalsize
% 
% \clearpage
% \setcounter{page}{1} %ne pas numéroter le sommaire: mettre 0
% \onehalfspacing
% 
% }
% 
% \makeatother% cinsérer page de garde
\usepackage{subfig}


\usepackage[tikz]{bclogo}
\newcounter{comptEncadre}
\renewcommand\thecomptEncadre{%\thesection.
\arabic{comptEncadre}}
\definecolor{processblue}{cmyk}{0.96,0,0,0}
\newenvironment{encadre}[2][false]{\refstepcounter{comptEncadre}
      %\addcontentsline{exp}{encadres}{\protect\numberline{\thecomptEncadre}#1}%
\begin{bclogo}[couleur=processblue!5,arrondi=0.1,
logo=\bcloupe,barre=none,couleurBord=blue!60!green,nobreak = #1]{ {\sc \textbf{Encadré \thecomptEncadre}} -  #2}
\smallskip
}{\end{bclogo}}


% nouvelle page de titre Kim
\usepackage{titling}
\setlength{\droptitle}{-8em}
\usepackage{lipsum}
\title{\textbf{TP1 : Basic functions for Supervised Machine Learning  } \medskip \\ \large \emph{Kim ANTUNEZ, Isabelle BERNARD (Group : Mr Denis)}}
\author{}

\renewcommand\maketitlehookc{\vspace{-10ex}}
% nouvelle page de titre Kim


\begin{document}

\maketitle


\vspace{-20truemm}

\hypertarget{part-1-mnist}{%
\section{PART 1 -- MNIST}\label{part-1-mnist}}

\hypertarget{cross-validation-with-gridsearchcv}{%
\subsection{Cross-validation with GridSearchCV}\label{cross-validation-with-gridsearchcv}}

\begin{tcolorbox}

Explain in your report what happens when we run \texttt{clf.fit(X\_train,\ y\_train)}
What is the complexity for each of the three following cases?

\end{tcolorbox}

The general objective here is to obtain a first classifier with the \textbf{KNN method}. To do that, we test different parameters of the KNN methods and choose the bests using a \textbf{cross validation}. That is to say that we test the KNN method by varying the number of neighbors from 1 to 5. The cross validation method used is called \textbf{the 3-fold Cross Validation} (CV) following those different steps:
1. we divide our training sample into 3 training sub-samples
2. we train the model on 2 samples and test it on the third one
3. we choose the parameter which has the best average test accuracy (see definition later) on the 3 samples.

\textbf{clf.fit(X\_train, y\_train)} applies what is described above to the training sample. It fits the model (learns from it) using X\_train as training data and y\_train as target values. The first clf (for classifier) used here is ``KNeighborsClassifier'' that is to say the k-nearest neighbors vote.

Let's imagine that you train a model on n points and it takes x minutes. If you train it on kn points, it takes kx minutes if the training time is linear, but sometimes it is more. For example, if it takes k2x, the training time is quadratic in the number of points. That is what we call the \textbf{complexity} of an algorithm. The question here is very broad (not very precise), because there are at least two different kinds of complexities : \textbf{training complexity and prediction complexity}.

We define the complexity using a Big-O measure. It provides us with an asymptotic upper bound for the growth rate of the runtime of the chosen algorithm. Calling n the number of training samples and p the number of features the complexity predicted for the three methods are :

\begin{itemize}
\item
  For the \textbf{knn} classifier : The parameter used for the algorithm is here `auto'. It selects `kd\_tree' if \(k < N/2\) and the `effective\_metric\_' is in the `VALID\_METRICS' list of `kd\_tree'. It selects `ball\_tree' if k \textless{} N/2 and the `effective\_metric\_' is not in the `VALID\_METRICS' list of `kd\_tree'. It selects `brute' if k \textgreater{}= N/2. For the brute-force method there is no training, (training complexity = \(O(1)\)), but classifying has a high cost (\(O(knp)\)). kd-tree and ball\_tree are \(O(pnlog(n))\) for training and \(O(klog(n))\) for prediction.
  . See precisions \href{https://towardsdatascience.com/k-nearest-neighbors-computational-complexity-502d2c440d5}{here} and \href{https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html}{here}.
\item
  Support Vector Machines (\textbf{SVM}) are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by the libsvm-based implementation (\texttt{SVC} function) scales between O(\(pn^2\)) and O(\(pn^3\)) depending on how efficiently the libsvm cache is used in practice (dataset dependent). But recent approaches like \href{https://www.cs.huji.ac.il/~shais/papers/SSSICML08.pdf}{this one} are inverse in the size of the training set. In the case of the \texttt{LinearSVC} method used in this ``TP'', it is indicated in the \href{https://scikit-learn.org/stable/modules/svm.html\#complexity}{documentation} that the implementation is much more efficient than its libsvm-based \texttt{SVC} counterpart and it's training complexity is \(O(pn)\) and prediction one remains \(O(n_{sv}*p)\) with \(n_{sv}\) the number of Support Vectors.
\item
  For \textbf{logistic regressions}, training complexity is \(O(np)\) and prediction one is \(O(p)\). See proof \href{https://levelup.gitconnected.com/train-test-complexity-and-space-complexity-of-logistic-regression-2cb3de762054}{here}.
\end{itemize}

\emph{Main sources : \href{https://medium.com/@paritoshkumar_5426/time-complexity-of-ml-models-4ec39fad2770}{here} and \href{https://www.thekerneltrip.com/machine/learning/computational-complexity-learning-algorithms/}{here}}.

\begin{tcolorbox}

What is the test accuracy? What would be the accuracy of random guess?

\end{tcolorbox}

Accuracy is the number of correctly predicted data points out of all the data points. It is used to determine which model is best at identifying relationships and patterns between variables in a dataset based on the input data or training data. The \texttt{accuracy\_score} function computes the accuracy, either the fraction (default) or the count (\texttt{normalize=False}) of correct predictions.

More formally, for a \textbf{binary problem} it is defined as followed.
\[
\texttt{accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]

\begin{longtable}[]{@{}lllll@{}}
\toprule
\begin{minipage}[b]{0.14\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.34\columnwidth}\raggedright
Actual : Class 1\strut
\end{minipage} & \begin{minipage}[b]{0.34\columnwidth}\raggedright
Actual : Class 0\strut
\end{minipage} & \begin{minipage}[b]{0.02\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[b]{0.02\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\midrule
\endhead
\begin{minipage}[t]{0.14\columnwidth}\raggedright
Predicted : Class 1\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright
TP (True Positive) Y\_true and Y\_pred in Class 1\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright
FP (False Positive) Y\_true in Class 0 and Y\_pred in Class 1\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\begin{minipage}[t]{0.14\columnwidth}\raggedright
Predicted : Class 0\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright
FN (False Negative) Y\_true in Class 1 and Y\_pred in Class 0\strut
\end{minipage} & \begin{minipage}[t]{0.34\columnwidth}\raggedright
TN (True Negative) Y\_true and Y\_pred in Class 0\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright
\strut
\end{minipage} & \begin{minipage}[t]{0.02\columnwidth}\raggedright
\strut
\end{minipage}\tabularnewline
\bottomrule
\end{longtable}

In \textbf{multilabel classification}, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1; otherwise it is 0.

If \(\hat{y}_i\) is the predicted value of the \(i\)-th sample and \(y_i\) is the corresponding true value, then the fraction of correct predictions over is defined as \(n_\text{samples}\). Here is the normalized accuracy score :
\[
\texttt{accuracy}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} 1(\hat{y}_i = y_i)
\]
See more details \href{https://scikit-learn.org/stable/modules/model_evaluation.html\#accuracy-score}{here}.

Here we comment the ``test accuracy'' that is to say the accuracy of the test sample and not on the training sample ! The test accuracy is here \textbf{0.875}. On a \textbf{random guess it would be 0.1} : one chance to be guess the right number out of 10 possible numbers (10 classes).

\begin{tcolorbox}

What is \texttt{LinearSVC()} classifier? Which kernel are we using? What is \texttt{C}? (this is a tricky question, try to find the answer online)

\end{tcolorbox}

\texttt{LinearSVC()} (Linear Support Vector Classification) is a fast implementation of Support Vector Machine Classification (SVM) for the case of a linear kernel. It is similar to \texttt{SVC} with parameter \texttt{kernel=’linear’}, but implemented in terms of \texttt{liblinear} rather than \texttt{libsvm}, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.
The main characteristics of this method are :
- the loss used is the \href{https://en.wikipedia.org/wiki/Hinge_loss}{`squared\_hinge'} (even if it is not indicated in the \href{https://scikit-learn.org/stable/modules/svm.html\#linearsvc}{general documentation} which is strange)
- to generate the multiclass problem, \texttt{LinearSVC()} uses \texttt{One-vs-All} (see example \href{http://eric.univ-lyon2.fr/~ricco/cours/slides/svm.pdf}{here}, slide 38).

More precisely, given training vectors \(x_i \in \mathbb{R}^p\), i=1,\ldots{}, n, in two classes, and a vector \(y \in \{1, -1\}^n\)
, our goal is to find \(w \in \mathbb{R}^p\) and \(b \in \mathbb{R}\) such that the prediction given by \(\text{sign} (w^T\phi(x) + b)\) is correct for most samples.
LinearSVC solves the following problem:
\(\min_ {w, b} \frac{1}{2} w^T w + C \sum_{i=1}\max(0, y_i (w^T \phi(x_i) + b))\),
where we make use of the hinge loss. This is the form that is directly optimized by LinearSVC, but unlike the dual form, this one does not involve inner products between samples, so the famous kernel trick cannot be applied. This is why only the linear kernel is supported by LinearSVC (\(\phi\) is the identity function).

The \textbf{C parameter} is a regularization or penalty parameter. SVM only work properly if the data is separable. Otherwise, we will penalize the loss of this non-separability (see \href{https://scikit-learn.org/stable/modules/svm.html\#svc}{here}) measuring the distance between the misclassified points and the separating hyperplane. C represents misclassification or error term. The misclassification or error term tells the SVM optimisation how much error is bearable. This is how you can control the trade-off between decision boundary and misclassification term. Concretely, when C is high, we penalize a lot for misclassification, which means that we classify lots of points correctly, also there is a chance to overfit.

\begin{tcolorbox}

What is the outcome of \texttt{np.logspace(-8,\ 8,\ 17,\ base=2)}? More generally, what is the outcome of \texttt{np.logspace(-a,\ b,\ k,\ base=m)}?

\end{tcolorbox}

\texttt{np.logspace(-8,\ 8,\ 17,\ base=2)} returns 17 numbers spaced evenly on a log scale. The sequence starts at \(2^{-8}\) and ends with \(2^{8}\).

\texttt{np.logspace(-a,\ b,\ k,\ base=m)} returns k numbers spaced evenly on a log scale (endpoint=True by default). The parameter \texttt{base} is the logarithmic base. In linear space, the sequence starts at \(m^{-a}\) and ends at \(m^b\).

It is equivalent to
1. divide the interval \([-a,b]\) into \((y_i)_{i=1..k}\) \(k\) equidistant points
2. return \(\left(m^{y_i}\right)_{i=1..k}\)

\begin{tcolorbox}

What is the meaning of the warnings? What is the parameter responsible for its appearence?

\end{tcolorbox}

Warnings are about the fact that the algorithm does not converge considering the maximum number of iterations given. The maximum number of iterations is given by the parameter \texttt{max\_iter} which is here set to \texttt{max\_iter=5000}.
In fact, there is no preprocessing (date are not normalize/standardized data). Therefore unscaled data can slow down or even prevent the convergence of many metric-based and gradient-based estimators. Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales.

\begin{tcolorbox}

What did we change with respect to the previous run of \texttt{LinearSVC()}?

\end{tcolorbox}

A pipeline allows us to perform several operations in a row. First, we renormalize the features with \texttt{MaxAbsScaler} (using the training data), in order to put them on the same scale.
This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1.

For each i-th component of each vector \((X_j)\), we probably divide by the highest value (in absolute value) that is to say \(X'_{i,j}=\frac{X_{i,j}}{X_{i_{max},j}}\) with \(i_{max}= \underset{j}{\max}|X_{i,j}|\) .

Second, we apply the same algorithm as before (svc, a LinearSVC) to fit the training data in a 3-fold CV validation (as before) to choose the best value of the C parameter which seems to be \texttt{C\ =\ 0.015625}.

\begin{tcolorbox}

Explain what happens if we execute

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{    pipe.fit(X_train, y_train)}
\NormalTok{    pipe.predict(X_test, y_test)}
\end{Highlighting}
\end{Shaded}

\end{tcolorbox}

\texttt{pipe.fit} works. It fits the dataset as before but not using a cross-validation but using the default \texttt{C} parameter (that is to say \ldots{}) and \texttt{max\_iter=5000}.

\texttt{pipe.predict} returns the following error : \texttt{TypeError:\ predict()\ takes\ 2\ positional\ arguments\ but\ 3\ were\ given}

The function does not work here because when we do a prevision, we do not need to enter the \texttt{Y} values, we just need the \texttt{X} ones.
This is why the following lines work (see below).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{    pipe.predict(X_test) }\CommentTok{#working}
\NormalTok{    pipe.score(X_test, y_test)  }\CommentTok{#working}
\end{Highlighting}
\end{Shaded}

\begin{tcolorbox}

what is the difference between \texttt{StandardScaler()} and \texttt{MaxAbsScaler()}? What are other scaling options available in \texttt{sklearn}?

\end{tcolorbox}

\begin{itemize}
\tightlist
\item
  \texttt{StandardScaler()} : Standardize features by removing the mean and scaling to unit variance
  The standard score of a sample x is calculated as:
  \(z = (x - u) / s\)
  where u is the mean of the training samples or zero if with\_mean=False, and s is the standard deviation of the training samples or one if with\_std=False.
\end{itemize}

Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform.
However, the outliers have an influence when computing the empirical mean and standard deviation which shrink the range of the feature values. StandardScaler therefore cannot guarantee balanced feature scales in the presence of outliers.

\begin{itemize}
\tightlist
\item
  \texttt{MaxAbsScaler()} : see previous question for the definition.
\end{itemize}

The \textbf{differences} between these two methods are the following :
* \texttt{MaxAbsScaler()} method does not shift/center the data, and thus does not destroy any sparsity, and thus can be applied to sparse CSR or CSC matrices, unlike \texttt{StandardScaler()}
* \texttt{MaxAbsScaler()} rescales the data et such that the absolute values are mapped in the range \([0, 1]\), unlike \texttt{StandardScaler()}
* On positive only data, \texttt{MaxAbsScaler()} behaves similarly to ``MinMaxScaler``` and therefore also suffers from the presence of large outliers.

Other scaling options available in \texttt{sklearn}:
1. \texttt{MinMaxScaler()} : rescales the data set such that all feature values are in the range \([0, 1]\) As StandardScaler, MinMaxScaler is very sensitive to the presence of outliers.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X_std }\OperatorTok{=}\NormalTok{ (X }\OperatorTok{-}\NormalTok{ X.}\BuiltInTok{min}\NormalTok{(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{)) }\OperatorTok{/}\NormalTok{ (X.}\BuiltInTok{max}\NormalTok{(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{) }\OperatorTok{-}\NormalTok{ X.}\BuiltInTok{min}\NormalTok{(axis}\OperatorTok{=}\DecValTok{0}\NormalTok{))}
\NormalTok{X_scaled }\OperatorTok{=}\NormalTok{ X_std }\OperatorTok{*}\NormalTok{ (}\BuiltInTok{max} \OperatorTok{-} \BuiltInTok{min}\NormalTok{) }\OperatorTok{+} \BuiltInTok{min}
\end{Highlighting}
\end{Shaded}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \texttt{RobustScaler()} : Unlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers (robust to outliers).
\item
  \texttt{Normalizer()} : The norm of each feature must be equal to 1. We can use many norms : \(L^1\), \(L^2\), \(L^\infty\) \ldots{}
\end{enumerate}

The whole list of preprocessing methods is available \href{https://scikit-learn.org/stable/modules/classes.html\#module-sklearn.preprocessing}{here}

\begin{tcolorbox}

using the previous code as an example achieve test accuracy \(\geq 0.9\). You can use any method from sklearn package. Give a mathematical description of the selected method. Explain the range of considered hyperparamers.

\end{tcolorbox}

We give here the examples of two methods but there are plenty of them.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Example 1 : SVC Classifier (other SVM classifier but not linear)
\end{enumerate}

Given training vectors \(x_i \in \mathbb{R}^p\), i=1,\ldots{}, n, in two classes, and a vector \(y \in \{1, -1\}^n\)
, our goal is to find \(w \in \mathbb{R}^p\) and \(b \in \mathbb{R}\) such that the prediction given by \(\text{sign} (w^T\phi(x) + b)\) is correct for most samples.
SVC solves the following problem:
\begin{align}\begin{aligned}\min_ {w, b, \zeta} \frac{1}{2} w^T w + C \sum_{i=1}^{n} \zeta_i\\\begin{split}\textrm {subject to } & y_i (w^T \phi (x_i) + b) \geq 1 - \zeta_i,\\
& \zeta_i \geq 0, i=1, ..., n\end{split}\end{aligned}\end{align}

Intuitively, we're trying to maximize the margin (by minimizing \(||w||^2 = w^Tw\)), while incurring a penalty when a sample is misclassified or within the margin boundary. Ideally, \(the value y_i (w^T \phi (x_i) + b)\) would be \(\geq 1\) for all samples, which indicates a perfect prediction. But problems are usually not always perfectly separable with a hyperplane, so we allow some samples to be at a distance \(\zeta_i\) from their correct margin boundary. The penalty term \(C\) controls the strengh of this penalty (as seen above).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Example 2 : Random forest
\end{enumerate}

The RandomForest algorithm is a perturb-and-combine technique specifically designed for trees. This means a diverse set of classifiers is created by introducing randomness in the classifier construction. The prediction of the ensemble is given as the averaged prediction of the individual classifiers. As other classifiers, forest classifiers have to be fitted with two arrays: a sparse or dense array X of size {[}n\_samples, n\_features{]} holding the training samples, and an array Y of size {[}n\_samples{]} holding the target values (class labels) for the training samples. Like decision trees, forests of trees also extend to multi-output problems (if Y is an array of size {[}n\_samples, n\_outputs{]}).

In random forests, each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. Furthermore, when splitting each node during the construction of a tree, the best split is found either from all input features or a random subset of size \texttt{max\_features}. The purpose of these two sources of randomness is to decrease the variance of the forest estimator. Indeed, individual decision trees typically exhibit high variance and tend to overfit. The injected randomness in forests yield decision trees with somewhat decoupled prediction errors. By taking an average of those predictions, some errors can cancel out. Random forests achieve a reduced variance by combining diverse trees, sometimes at the cost of a slight increase in bias. In practice the variance reduction is often significant hence yielding an overall better model.

In contrast to the original publication, the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class. We can vary the range of several parameters. Here we chose to move \texttt{n\_estimators}. Below the different parameters possible :

\begin{verbatim}
* n_estimators = number of trees in the foreset
* max_features = max number of features considered for splitting a node
* max_depth = max number of levels in each decision tree
* min_samples_split = min number of data points placed in a node before the node is split
* min_samples_leaf = min number of data points allowed in a leaf node
* bootstrap = method for sampling data points (with or without replacement)
\end{verbatim}

The code corresponding to the 2 methods is in Annex \ref{annexe:annexe1}.

\hypertarget{visualizing-errors}{%
\subsection{Visualizing errors}\label{visualizing-errors}}

\begin{tcolorbox}

There is a mistake in the following chunk of code. Fix it.

\end{tcolorbox}

The line with a mistake is the following :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{axes[}\DecValTok{1}\NormalTok{, j].bar(np.arange(}\DecValTok{10}\NormalTok{), clf4.predict_proba(image.reshape(}\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{)))  }\CommentTok{# MISTAKE !}
\end{Highlighting}
\end{Shaded}

If we execute the code line by line we find the following error
\texttt{only\ size-1\ arrays\ can\ be\ converted\ to\ Python\ scalars}

It means that the two following objects do not have the same dimensions :

\begin{Shaded}
\begin{Highlighting}[]
\BuiltInTok{print}\NormalTok{(np.arange(}\DecValTok{10}\NormalTok{))  }\CommentTok{# 1 dimension}
\BuiltInTok{print}\NormalTok{(clf4.predict_proba(image.reshape(}\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{)))  }\CommentTok{# 2 dimensions => must be 1}
\end{Highlighting}
\end{Shaded}

The line must be replaced by :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{axes[}\DecValTok{1}\NormalTok{, j].bar(np.arange(}\DecValTok{10}\NormalTok{), clf4.predict_proba(image.reshape(}\DecValTok{1}\NormalTok{, }\DecValTok{-1}\NormalTok{))[}\DecValTok{0}\NormalTok{]) }\CommentTok{# CORRECTION ! }
\end{Highlighting}
\end{Shaded}

\hypertarget{changing-the-loss-function}{%
\subsection{Changing the Loss function}\label{changing-the-loss-function}}

\begin{tcolorbox}

What is \texttt{balanced\_accuracy\_score}? Write its mathematical mathematical description.

\end{tcolorbox}

The \texttt{balanced\_accuracy\_score} function computes the balanced accuracy, which \textbf{avoids inflated performance estimates on imbalanced datasets}(when classes are over or under-representated). It is the macro-average of recall scores per class or, equivalently, raw accuracy where each sample is weighted according to the inverse prevalence of its true class. Thus for balanced datasets, the score is equal to accuracy.

In the \emph{binary case}, balanced accuracy is equal to the arithmetic mean of sensitivity (true positive rate) and specificity (true negative rate), or the area under the ROC curve with binary predictions rather than scores:

\[
\texttt{balanced-accuracy} = \frac{1}{2}\left( \frac{TP}{TP + FN} + \frac{TN}{TN + FP}\right )
\]

In the \emph{multiclass case}, balanced accuracy is defined as the following, given \(y_i\) the true value of the \(i\)-th sample, predicted value \(\hat{y}_i\) and \(w_i\) is the corresponding sample weight.

\[
balanced-accuracy(y,\hat y,w)=\frac{1}{\sum \hat w_i} \sum_i 1_{(\hat y_i = y_i)}\hat w_i
\quad \text{ with } \quad \hat{w}_i = \frac{w_i}{\sum_j{1(y_j = y_i) w_j}}
\]

\emph{Source: \href{https://scikit-learn.org/stable/modules/model_evaluation.html\#balanced-accuracy-score}{here}.}

\begin{tcolorbox}

What is the confusion matrix? What are the conclusions that we can draw from the \texttt{confusion\_matrix(y\_test,\ clf4.predict(X\_test))}

\end{tcolorbox}

By definition a confusion matrix \(C\) is such that \(C_{i,j}\) is equal to the number of observations known to be in group \(i\) and predicted to be in group \(j\).
Here, when can see for example that 0 are well identified (all predicted as being 0's), 3 are sometimes (3 times out of 23) identified as 5, 8 are also sometimes (3 times out of 17) identified as 5.

\hypertarget{part-2-problem-code-in-annex}{%
\section{\texorpdfstring{PART 2 -- Problem (Code in Annex \ref{annexe:annexe2})}{PART 2 -- Problem (Code in Annex )}}\label{part-2-problem-code-in-annex}}

\hypertarget{first-thought}{%
\subsection{First thought}\label{first-thought}}

\begin{tcolorbox}

Propose a loss function that would address our needs. Explain your choice.

\end{tcolorbox}

For this problem, our \textbf{FIRST IDEA} was to define two sets Class 1 = \{0,1,2,3,4\} and Class 0 = \{5,6,7,8,9\}.

In order to find a proper loss function, we use the definition of the precision score.
In fact, we want to minimize Y\_pred in class 1 when Y\_true in class 0 (reduce False Positive rate).
In a binary classification task, the terms `'positive'' and `'negative'' refer to the classifier's prediction, and the terms `'true'' and `'false'' refer to whether that prediction corresponds to the external judgment (sometimes known as the `'observation''). In this context, we can define the notiont of precision as : \(\text{precision} = \frac{tp}{tp + fp},\) which is the indicator which is the most interesting to answer to this problem.

\textbf{\faArrowCircleRight{} After training the model, we compare our results with the previous confusion matrix to verify that the bottom right square has evolved well : the sum of the last five lines and the first five columns should be smaller.}

\begin{tcolorbox}

Following above examples, make an ML pipeline that uses \emph{your} loss function and finds appropriate classifiers.

\end{tcolorbox}

We tested two ML methods here : LinearSVC and SVC with the kernel rbf. The conclusions are the following :

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  The sum of the left-bottom corner of the confusion-matrix of LinearSVC is smaller and thus better for the new method based on precision (see following matrix on the left) than for the method based on accuracy (matrix on the right.
\end{enumerate}

\footnotesize

\begin{verbatim}
    [1 0 0 1 0]  [0 0 0 0 0]
    [1 2 1 0 0]  [0 1 1 0 0]
    [0 0 0 0 1]  [0 0 0 0 0]
    [0 2 0 1 0]  [0 1 0 1 1]
    [0 0 0 0 2]  [0 0 0 0 0]
\end{verbatim}

\normalsize

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  The accuracy of the model obtained with the kernel rbf of SVC method seems to be better than with linear kernel.
\end{enumerate}

\textbf{\faArrowCircleRight{} However, this method does not allow to penalize the error of classification inside the two classes (1 and 0). For example, if I predict a 0 instead of a 1 it is not penalized in the loss function whereas it should be.}

\hypertarget{second-thought}{%
\subsection{Second thought}\label{second-thought}}

\begin{tcolorbox}

Propose a loss function that would address our needs. Explain your choice.

\end{tcolorbox}

Our \textbf{SECOND IDEA} was to change the loss function in another way to take into account the fact that we must penalize if we predict the wrong number even if the actual or predicted values are both small or large

In the usual classification that we made above, we used the following loss
\[l_1(y,\hat{y}) = 1_{\hat{y} \ne y}\]

Here, we can modify a little bit to show that we do not like if \(y \in H = \{5, 6, 7, 8, 9\}\) and \(\hat{y} \in L = \{0, 1, 2, 3, 4\}\).

\[
l_2(y,\hat{y}) = 1_{(\hat{y} \ne y) \& [(y \notin H) \text{ or } (\hat{y} \notin L)]} + \alpha * 1_{(\hat{y} \ne y) \& (y \in H) \& (\hat{y} \in L)}
\]

where \(\alpha > 1\) reflects the aversion that you have when \(y \in H\) and \(\hat{y} \in L\).

Then, we need to define the scoring parameter to evaluate the predictions on the test set. All scorer objects follow the convention that higher return values are better than lower return values.

Previously we saw, two kinds of scorers the Accuracy classification score and the \textbf{Balanced} accuracy classification score.

Here, we try to adapte theses scorers to take into account that we really don't like when \(y \in H\) and \(\hat{y} \in L\). We propose two new scorers :

\begin{itemize}
\tightlist
\item
  The Accuracy ``2'' classification score.
\end{itemize}

\[
\texttt{accuracy}_{2}(y, \hat{y}) = 1- (\frac{1}{\alpha * n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} l_2(y,\hat{y})) = 1- (\frac{1}{\alpha * n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} 1_{(\hat{y} \ne y) \& [(y \notin H) \text{ or } (\hat{y} \notin L)]} + \alpha * 1_{(\hat{y} \ne y) \& (y \in H) \& (\hat{y} \in L)}) 
\]

\begin{itemize}
\tightlist
\item
  The Balanced accuracy ``2'' classification score.
\end{itemize}

\[
balanced-accuracy_2(y,\hat y,w)=1 - (\frac{1}{\alpha * \sum \hat w_i} \sum_i l_2(y,\hat{y}) \hat w_i) \quad \text{with still} \quad \hat{w}_i = \frac{w_i}{\sum_j{1(y_j = y_i) w_j}}
\]

\begin{tcolorbox}

Following above examples, make an ML pipeline that uses \emph{your} loss function and finds appropriate classifiers.

\end{tcolorbox}

Now that we have defined the loss and the score functions, let's try to use this score with the 3 different methods (KNN, LinearSVC and LogisticRegression) of machine learning we discovered for this TP and evaluate them. Note that we still want that the sum of the last five lines and the first five columns of the confusion matrix should be smaller than before.

\textbf{\faArrowCircleRight{} Whereas the change of the loss doesn't change the model obtained with the knn method, with the LinearSVC, we obtained different results from the previous models, with a confusion matrix evolving in the good way (smaller sum of the bottom left quarter). See details in the code.}

\clearpage

\newpage

\hypertarget{appendix-appendix}{%
\appendix}


\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}
\setcounter{page}{0}
\pagenumbering{roman}

\hypertarget{annexe:annexe1}{%
\section{Code for SVC and Random Forests}\label{annexe:annexe1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Example 1 : SVC Classifier (other SVM classifier but not linear)}
\ImportTok{from}\NormalTok{ sklearn.svm }\ImportTok{import}\NormalTok{ SVC}
\NormalTok{svc2 }\OperatorTok{=}\NormalTok{ SVC(max_iter}\OperatorTok{=}\DecValTok{5000}\NormalTok{) }\CommentTok{# by default : rbf kernel}

\NormalTok{pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{'scaler'}\NormalTok{, MaxAbsScaler()), (}\StringTok{'svc'}\NormalTok{, svc2)])}
\NormalTok{parameters5 }\OperatorTok{=}\NormalTok{ \{}\StringTok{'svc__C'}\NormalTok{: np.logspace(}\OperatorTok{-}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{17}\NormalTok{, base}\OperatorTok{=}\DecValTok{2}\NormalTok{)\} }\CommentTok{# defining parameter space}
\NormalTok{clf5 }\OperatorTok{=}\NormalTok{ GridSearchCV(pipe, parameters5, cv}\OperatorTok{=}\DecValTok{3}\NormalTok{)}
\NormalTok{clf5.fit(X_train, y_train)}

\BuiltInTok{print}\NormalTok{(}\StringTok{'Returned hyperparameter: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf5.best_params_))}
\BuiltInTok{print}\NormalTok{(}\StringTok{'Best classification accuracy in train is: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf5.best_score_))}
\BuiltInTok{print}\NormalTok{(}\StringTok{'Classification accuracy on test is: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf5.score(X_test, y_test)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Returned hyperparameter: {'svc__C': 8.0}
Best classification accuracy in train is: 0.9190022106064085
Classification accuracy on test is: 0.945
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Example 2 : Random forest}

\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestClassifier}
\ImportTok{from}\NormalTok{ sklearn.datasets }\ImportTok{import}\NormalTok{ make_classification}
\ImportTok{from}\NormalTok{ sklearn.ensemble }\ImportTok{import}\NormalTok{ RandomForestRegressor}
\ImportTok{from}\NormalTok{ sklearn.model_selection }\ImportTok{import}\NormalTok{ RandomizedSearchCV }\CommentTok{# Number of trees in random forest}

\ImportTok{from}\NormalTok{ pprint }\ImportTok{import}\NormalTok{ pprint}\CommentTok{# Look at parameters used by our current forest}
\NormalTok{rf }\OperatorTok{=}\NormalTok{ RandomForestRegressor(random_state }\OperatorTok{=} \DecValTok{42}\NormalTok{)}
\BuiltInTok{print}\NormalTok{(}\StringTok{'Parameters currently in use:}\CharTok{\textbackslash{}n}\StringTok{'}\NormalTok{)}
\NormalTok{pprint(rf.get_params())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Parameters currently in use:

{'bootstrap': True,
 'ccp_alpha': 0.0,
 'criterion': 'mse',
 'max_depth': None,
 'max_features': 'auto',
 'max_leaf_nodes': None,
 'max_samples': None,
 'min_impurity_decrease': 0.0,
 'min_impurity_split': None,
 'min_samples_leaf': 1,
 'min_samples_split': 2,
 'min_weight_fraction_leaf': 0.0,
 'n_estimators': 100,
 'n_jobs': None,
 'oob_score': False,
 'random_state': 42,
 'verbose': 0,
 'warm_start': False}
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{rf }\OperatorTok{=}\NormalTok{ RandomForestClassifier(max_depth}\OperatorTok{=}\DecValTok{10}\NormalTok{, random_state}\OperatorTok{=}\DecValTok{0}\NormalTok{) }\CommentTok{# defining classifier}
\NormalTok{n_estimators }\OperatorTok{=}\NormalTok{ [}\BuiltInTok{int}\NormalTok{(x) }\ControlFlowTok{for}\NormalTok{ x }\KeywordTok{in}\NormalTok{ np.linspace(start }\OperatorTok{=} \DecValTok{200}\NormalTok{, stop }\OperatorTok{=} \DecValTok{2000}\NormalTok{, num }\OperatorTok{=} \DecValTok{10}\NormalTok{)]}
\NormalTok{parameters }\OperatorTok{=}\NormalTok{ \{}\StringTok{'n_estimators'}\NormalTok{: n_estimators\}}
\NormalTok{clf6 }\OperatorTok{=}\NormalTok{ GridSearchCV(rf, parameters, cv}\OperatorTok{=}\DecValTok{3}\NormalTok{) }\CommentTok{#cross-validation : method 3-fold.}
\NormalTok{clf6.fit(X_train, y_train)}

\BuiltInTok{print}\NormalTok{(}\StringTok{'Returned hyperparameter: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf6.best_params_))}
\BuiltInTok{print}\NormalTok{(}\StringTok{'Best classification accuracy in train is: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf6.best_score_))}
\BuiltInTok{print}\NormalTok{(}\StringTok{'Classification accuracy on test is: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf6.score(X_test, y_test)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Returned hyperparameter: {'n_estimators': 1200}
Best classification accuracy in train is: 0.9115044579812196
Classification accuracy on test is: 0.93
\end{verbatim}

\newpage

\hypertarget{annexe:annexe2}{%
\section{Code for PART 2 -- Problem}\label{annexe:annexe2}}

\hypertarget{first-thought-1}{%
\subsection{First thought}\label{first-thought-1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Define New precision score function with 2 class : Class 1 = \{0,1,2,3,4\} and Class 0 = \{5,6,7,8,9\}}
\KeywordTok{def}\NormalTok{ custom_precision_score(y_true, y_pred):}
    \CommentTok{#Class 1 = \{0,1,2,3,4\} and Class 0 = \{5,6,7,8,9\}}
    \CommentTok{#Calcul TP (True Positive) = y_true and y_pred in class 1}
\NormalTok{    true_positive }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{((y_true.astype(}\BuiltInTok{int}\NormalTok{) }\OperatorTok{<} \DecValTok{5}\NormalTok{ ) }\OperatorTok{&}\NormalTok{ (y_pred.astype(}\BuiltInTok{int}\NormalTok{) }\OperatorTok{<} \DecValTok{5}\NormalTok{))}
    \CommentTok{#Calcul FP (False Positive) = y_true in class 0 and y_pred in class 1}
\NormalTok{    false_positive }\OperatorTok{=}\NormalTok{ np.}\BuiltInTok{sum}\NormalTok{((y_true.astype(}\BuiltInTok{int}\NormalTok{) }\OperatorTok{>} \DecValTok{4}\NormalTok{) }\OperatorTok{&}\NormalTok{ (y_pred.astype(}\BuiltInTok{int}\NormalTok{) }\OperatorTok{<} \DecValTok{5}\NormalTok{))}
    \ControlFlowTok{return}\NormalTok{ true_positive }\OperatorTok{/}\NormalTok{ (true_positive }\OperatorTok{+}\NormalTok{ false_positive)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ use_svc(model):}
    \CommentTok{#define the scorer}
\NormalTok{    scorer }\OperatorTok{=}\NormalTok{ make_scorer(custom_precision_score, greater_is_better}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{    pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{'scaler'}\NormalTok{, MaxAbsScaler()), (}\StringTok{'svc'}\NormalTok{, model)])}
\NormalTok{    parameters }\OperatorTok{=}\NormalTok{ \{}\StringTok{'svc__C'}\NormalTok{: np.logspace(}\OperatorTok{-}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{17}\NormalTok{, base}\OperatorTok{=}\DecValTok{2}\NormalTok{)\} }\CommentTok{# defining parameter space}
\NormalTok{    clf }\OperatorTok{=}\NormalTok{ GridSearchCV(pipe, parameters, cv}\OperatorTok{=}\DecValTok{3}\NormalTok{, scoring}\OperatorTok{=}\NormalTok{scorer)}
\NormalTok{    clf.fit(X_train, y_train)}
    \ControlFlowTok{return}\NormalTok{ clf}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#Tests on different models}
\KeywordTok{def}\NormalTok{ evaluation_model(model):}
\NormalTok{    grid }\OperatorTok{=}\NormalTok{ use_svc(model)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'Returned hyperparameter: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(grid.best_params_))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'Best accuracy in train is: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(grid.best_score_))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'Accuracy on test is: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(grid.score(X_test, y_test)))}
\NormalTok{    best_model }\OperatorTok{=}\NormalTok{ grid.best_estimator_}
\NormalTok{    y_pred }\OperatorTok{=}\NormalTok{ best_model.predict(X_test)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'(Check custom precision score in test is the same as accuracy : }\SpecialCharTok{\{\}}\StringTok{)'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(custom_precision_score(y_test, y_pred)))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'Confusion matrix: }\CharTok{\textbackslash{}n}\StringTok{ }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(confusion_matrix(y_test, y_pred)))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{from}\NormalTok{ sklearn.svm }\ImportTok{import}\NormalTok{ SVC}

\NormalTok{svc_linear }\OperatorTok{=}\NormalTok{ LinearSVC(max_iter}\OperatorTok{=}\DecValTok{5000}\NormalTok{)}
\NormalTok{svc }\OperatorTok{=}\NormalTok{ SVC(max_iter}\OperatorTok{=}\DecValTok{5000}\NormalTok{)}

\NormalTok{dict_of_models }\OperatorTok{=}\NormalTok{ \{}\StringTok{'Linear SVC'}\NormalTok{: svc_linear,}
                  \StringTok{'SVC (kernel=rbf)'}\NormalTok{: svc}
\NormalTok{                  \}}
\ControlFlowTok{for}\NormalTok{ name, model }\KeywordTok{in}\NormalTok{ dict_of_models.items():}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'------ Model : }\SpecialCharTok{\{\}}\StringTok{ ------ '}\NormalTok{.}\BuiltInTok{format}\NormalTok{(name))}
\NormalTok{    evaluation_model(model)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{"}\CharTok{\textbackslash{}n}\StringTok{"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
------ Model : Linear SVC ------ 
Returned hyperparameter: {'svc__C': 0.125}
Best accuracy in train is: 0.9222826688026527
Accuracy on test is: 0.9279279279279279
(Check custom precision score in test is the same as accuracy : 0.9279279279279279)
Confusion matrix: 
 [[22  0  0  0  0  0  0  0  0  0]
 [ 0 23  0  2  0  0  0  0  0  1]
 [ 1  0 14  1  0  0  0  0  0  0]
 [ 0  0  1 20  0  0  0  0  1  1]
 [ 0  1  1  0 17  0  0  0  1  0]
 [ 1  0  0  1  0  7  0  1  0  0]
 [ 1  0  0  0  0  1 20  0  1  1]
 [ 0  0  0  0  1  0  0 14  0  1]
 [ 0  1  0  1  0  2  1  0 12  0]
 [ 0  0  0  0  2  0  0  2  1 21]]


------ Model : SVC (kernel=rbf) ------ 
Returned hyperparameter: {'svc__C': 2.0}
Best accuracy in train is: 0.9379540095272763
Accuracy on test is: 0.9629629629629629
(Check custom precision score in test is the same as accuracy : 0.9629629629629629)
Confusion matrix: 
 [[22  0  0  0  0  0  0  0  0  0]
 [ 0 24  1  1  0  0  0  0  0  0]
 [ 0  0 16  0  0  0  0  0  0  0]
 [ 0  0  0 21  0  1  0  0  0  1]
 [ 0  0  1  0 18  0  0  0  0  1]
 [ 0  0  0  0  0 10  0  0  0  0]
 [ 0  1  1  0  0  0 22  0  0  0]
 [ 0  0  0  0  0  0  0 16  0  0]
 [ 0  1  0  1  0  0  0  0 15  0]
 [ 0  0  0  0  0  0  0  1  1 24]]
\end{verbatim}

\hypertarget{second-thought-1}{%
\subsection{Second thought}\label{second-thought-1}}

\begin{Shaded}
\begin{Highlighting}[]
\ImportTok{import}\NormalTok{ pandas }\ImportTok{as}\NormalTok{ pd}

\CommentTok{# this function returns a vector containing the loss for each pair of (y_true, y_pred)}
\KeywordTok{def}\NormalTok{ my_custom_loss_func(y_true,y_pred, alpha):}
\NormalTok{    df }\OperatorTok{=}\NormalTok{ pd.DataFrame(\{}\StringTok{'y_true'}\NormalTok{: [}\BuiltInTok{int}\NormalTok{(s) }\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ y_true],}\StringTok{'y_pred'}\NormalTok{: [}\BuiltInTok{int}\NormalTok{(s) }\ControlFlowTok{for}\NormalTok{ s }\KeywordTok{in}\NormalTok{ y_pred]\})}
\NormalTok{    df[}\StringTok{'loss'}\NormalTok{] }\OperatorTok{=} \DecValTok{1}\OperatorTok{*}\NormalTok{ (df[}\StringTok{'y_true'}\NormalTok{] }\OperatorTok{!=}\NormalTok{ df[}\StringTok{'y_pred'}\NormalTok{])}
\NormalTok{    df[}\StringTok{'loss'}\NormalTok{] }\OperatorTok{=}\NormalTok{ df[}\StringTok{'loss'}\NormalTok{] }\OperatorTok{+}\NormalTok{ (alpha}\DecValTok{-1}\NormalTok{)}\OperatorTok{*}\NormalTok{((df[}\StringTok{'y_true'}\NormalTok{] }\OperatorTok{>}\DecValTok{4}\NormalTok{) }\OperatorTok{&}\NormalTok{ (df[}\StringTok{'y_pred'}\NormalTok{] }\OperatorTok{<} \DecValTok{5}\NormalTok{))}
    \ControlFlowTok{return}\NormalTok{ df[}\StringTok{'loss'}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# an example to illustrate it}
\NormalTok{y_true }\OperatorTok{=}\NormalTok{ [}\StringTok{'9'}\NormalTok{, }\StringTok{'9'}\NormalTok{, }\StringTok{'9'}\NormalTok{] }\CommentTok{#we have 3 nines in the dataset}
\NormalTok{y_pred }\OperatorTok{=}\NormalTok{ [}\StringTok{'9'}\NormalTok{, }\StringTok{'8'}\NormalTok{, }\StringTok{'1'}\NormalTok{] }
\CommentTok{#the first one is well-predicted (loss 0),}
\CommentTok{#the second one is bad predicted but still high (loss 1)}
\CommentTok{#the last one is very bad predicted (with a low number) (loss alpha=2)}
\BuiltInTok{print}\NormalTok{(my_custom_loss_func(y_true,y_pred, alpha}\OperatorTok{=}\DecValTok{2}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
0    0
1    1
2    2
Name: loss, dtype: int32
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{#both functions evaluate the quality of the prediction.}

\CommentTok{#accuracy_2 function}
\KeywordTok{def}\NormalTok{ accuracy_2(y_true,y_pred, alpha):}
\NormalTok{    nsamples }\OperatorTok{=} \BuiltInTok{len}\NormalTok{(y_true)}
\NormalTok{    loss }\OperatorTok{=}\NormalTok{ my_custom_loss_func(y_true,y_pred,alpha)}
\NormalTok{    score }\OperatorTok{=} \DecValTok{1}\OperatorTok{-}\NormalTok{((}\DecValTok{1}\OperatorTok{/}\NormalTok{(alpha}\OperatorTok{*}\NormalTok{nsamples)) }\OperatorTok{*} \BuiltInTok{sum}\NormalTok{(loss))}
    \ControlFlowTok{return}\NormalTok{ score}

\CommentTok{#balanced_accuracy_2 function}
\KeywordTok{def}\NormalTok{ balanced_accuracy_2(y_true,y_pred, alpha):}
\NormalTok{    C }\OperatorTok{=}\NormalTok{ confusion_matrix(y_true, y_pred, sample_weight}\OperatorTok{=}\VariableTok{None}\NormalTok{)    }
    \ControlFlowTok{with}\NormalTok{ np.errstate(divide}\OperatorTok{=}\StringTok{'ignore'}\NormalTok{, invalid}\OperatorTok{=}\StringTok{'ignore'}\NormalTok{):}
\NormalTok{        wi_hat_par_cat }\OperatorTok{=} \DecValTok{1}\OperatorTok{/}\NormalTok{C.}\BuiltInTok{sum}\NormalTok{(axis}\OperatorTok{=}\DecValTok{1}\NormalTok{)}
    \ControlFlowTok{if}\NormalTok{ np.}\BuiltInTok{any}\NormalTok{(np.isinf(wi_hat_par_cat)):}
\NormalTok{        wi_hat_par_cat }\OperatorTok{=}\NormalTok{ wi_hat_par_cat[}\OperatorTok{~}\NormalTok{np.isinf(wi_hat_par_cat)]    }

\NormalTok{    wi_hat}\OperatorTok{=}\NormalTok{ [}\VariableTok{None}\NormalTok{] }\OperatorTok{*} \BuiltInTok{len}\NormalTok{(y_true)}
    \ControlFlowTok{for}\NormalTok{ i }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(y_true)):     }\CommentTok{#np.unique(y_true):}
        \ControlFlowTok{for}\NormalTok{ j }\KeywordTok{in} \BuiltInTok{range}\NormalTok{(}\BuiltInTok{len}\NormalTok{(wi_hat_par_cat)): }\CommentTok{#np.unique(y_true): }
            \ControlFlowTok{if}\NormalTok{ y_true[i]}\OperatorTok{==}\NormalTok{np.unique(y_true)[j]: }
\NormalTok{                wi_hat[i]}\OperatorTok{=}\NormalTok{wi_hat_par_cat[j]}
\NormalTok{    loss }\OperatorTok{=}\NormalTok{ my_custom_loss_func(y_true,y_pred,alpha)}
\NormalTok{    score }\OperatorTok{=} \DecValTok{1}\OperatorTok{-}\NormalTok{((}\DecValTok{1}\OperatorTok{/}\NormalTok{(alpha}\OperatorTok{*}\BuiltInTok{sum}\NormalTok{(wi_hat))) }\OperatorTok{*} \BuiltInTok{sum}\NormalTok{(loss}\OperatorTok{*}\NormalTok{wi_hat))}
    \ControlFlowTok{return}\NormalTok{(score)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# going back to the previous example to illustrate it}
\NormalTok{y_true }\OperatorTok{=}\NormalTok{ [}\StringTok{'9'}\NormalTok{, }\StringTok{'9'}\NormalTok{, }\StringTok{'9'}\NormalTok{] }
\NormalTok{y_pred }\OperatorTok{=}\NormalTok{ [}\StringTok{'9'}\NormalTok{, }\StringTok{'8'}\NormalTok{, }\StringTok{'1'}\NormalTok{] }
\BuiltInTok{print}\NormalTok{(}\StringTok{"accuracy_2 : "}\NormalTok{, accuracy_2(y_true,y_pred,alpha}\OperatorTok{=}\DecValTok{2}\NormalTok{))}
\BuiltInTok{print}\NormalTok{(}\StringTok{"balanced_accuracy_2 : "}\NormalTok{, balanced_accuracy_2(y_true,y_pred,alpha}\OperatorTok{=}\DecValTok{2}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
accuracy_2 :  0.5
balanced_accuracy_2 :  0.5
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# function which calculates the sum of the last five lines and five first columns of C}
\KeywordTok{def}\NormalTok{ sum_unwanted(clf):}
\NormalTok{    C}\OperatorTok{=}\NormalTok{confusion_matrix(y_test, clf.predict(X_test))}
\NormalTok{    res }\OperatorTok{=} \BuiltInTok{sum}\NormalTok{(C[}\DecValTok{5}\NormalTok{][:}\DecValTok{4}\NormalTok{])}\OperatorTok{+}\BuiltInTok{sum}\NormalTok{(C[}\DecValTok{6}\NormalTok{][:}\DecValTok{5}\NormalTok{])}\OperatorTok{+}\BuiltInTok{sum}\NormalTok{(C[}\DecValTok{7}\NormalTok{][:}\DecValTok{6}\NormalTok{])}\OperatorTok{+}\BuiltInTok{sum}\NormalTok{(C[}\DecValTok{8}\NormalTok{][:}\DecValTok{7}\NormalTok{])}\OperatorTok{+}\BuiltInTok{sum}\NormalTok{(C[}\DecValTok{9}\NormalTok{][:}\DecValTok{8}\NormalTok{])}
    \ControlFlowTok{return}\NormalTok{(res)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# function which evaluates the model}
\KeywordTok{def}\NormalTok{ evaluation_model(clf):}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'Returned hyperparameter: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf.best_params_))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'Best classification accuracy2 in train is: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf.best_score_))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'Classification accuracy2 on test is: }\SpecialCharTok{\{\}}\StringTok{'}\NormalTok{.}\BuiltInTok{format}\NormalTok{(clf.score(X_test, y_test)))}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'Confusion matrix: }\CharTok{\textbackslash{}n}\StringTok{'}\NormalTok{, confusion_matrix(y_test, clf.predict(X_test)))}
\end{Highlighting}
\end{Shaded}

\hypertarget{knn}{%
\subsubsection{KNN}\label{knn}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ use_knn(alpha, balanced}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ balanced:}
\NormalTok{        scorer }\OperatorTok{=}\NormalTok{ make_scorer(accuracy_2, alpha}\OperatorTok{=}\NormalTok{alpha)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        scorer }\OperatorTok{=}\NormalTok{ make_scorer(balanced_accuracy_2, alpha}\OperatorTok{=}\NormalTok{alpha)   }
\NormalTok{    knn }\OperatorTok{=}\NormalTok{ KNeighborsClassifier() }\CommentTok{# defining classifier}
\NormalTok{    parameters }\OperatorTok{=}\NormalTok{ \{}\StringTok{'n_neighbors'}\NormalTok{: [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{]\} }\CommentTok{# defining parameter space}
\NormalTok{    clf }\OperatorTok{=}\NormalTok{ GridSearchCV(knn, parameters, cv}\OperatorTok{=}\DecValTok{3}\NormalTok{, scoring}\OperatorTok{=}\NormalTok{scorer)}
\NormalTok{    clf.fit(X_train, y_train)}
    \ControlFlowTok{return}\NormalTok{(clf)}
\end{Highlighting}
\end{Shaded}

Si \(\alpha = 1\), we logically have the same results as the beginning of this TP:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf7_alpha1 }\OperatorTok{=}\NormalTok{ use_knn(alpha}\OperatorTok{=}\DecValTok{1}\NormalTok{, balanced}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{evaluation_model(clf7_alpha1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Returned hyperparameter: {'n_neighbors': 1}
Best classification accuracy2 in train is: 0.891497944721333
Classification accuracy2 on test is: 0.875
Confusion matrix: 
 [[21  0  0  0  0  0  1  0  0  0]
 [ 0 26  0  0  0  0  0  0  0  0]
 [ 0  0 14  0  0  2  0  0  0  0]
 [ 0  0  0 19  0  2  0  0  1  1]
 [ 0  1  0  0 17  0  0  0  0  2]
 [ 0  0  0  0  1  7  1  0  1  0]
 [ 0  0  0  0  0  1 23  0  0  0]
 [ 0  0  0  0  1  0  0 15  0  0]
 [ 0  1  0  1  0  0  0  0 14  1]
 [ 1  1  0  0  2  0  0  3  0 19]]
\end{verbatim}

We try to increase the value of \(\alpha\) that is to say to penalize more when \(y \in H\) and \(\hat{y} \in L\). let's try \(\alpha=10\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf7_alpha10 }\OperatorTok{=}\NormalTok{ use_knn(alpha}\OperatorTok{=}\DecValTok{10}\NormalTok{, balanced}\OperatorTok{=}\VariableTok{False}\NormalTok{)}
\NormalTok{evaluation_model(clf7_alpha10)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Returned hyperparameter: {'n_neighbors': 1}
Best classification accuracy2 in train is: 0.9590000045022534
Classification accuracy2 on test is: 0.9515
Confusion matrix: 
 [[21  0  0  0  0  0  1  0  0  0]
 [ 0 26  0  0  0  0  0  0  0  0]
 [ 0  0 14  0  0  2  0  0  0  0]
 [ 0  0  0 19  0  2  0  0  1  1]
 [ 0  1  0  0 17  0  0  0  0  2]
 [ 0  0  0  0  1  7  1  0  1  0]
 [ 0  0  0  0  0  1 23  0  0  0]
 [ 0  0  0  0  1  0  0 15  0  0]
 [ 0  1  0  1  0  0  0  0 14  1]
 [ 1  1  0  0  2  0  0  3  0 19]]
\end{verbatim}

The accuracy is better than the previous one but, be careful, we cannot compare the two accuracies because they are not using the same formula because it depends on the value of \(\alpha\).

Unfortunately, the confusion matrix does not change because the best model remains the same (\texttt{n\_neighbours\ =\ 1}) and do not decrease. However, this is totally normal because the parameter \texttt{n\_neighbours\ =\ 1} already corresponds to the minimum :

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ n }\KeywordTok{in}\NormalTok{ [}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{]:}
\NormalTok{    knn }\OperatorTok{=}\NormalTok{ KNeighborsClassifier(n_neighbors }\OperatorTok{=}\NormalTok{ n)}\OperatorTok{;}
\NormalTok{    knn.fit(X_train, y_train)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'With parameter '}\NormalTok{,n, }\StringTok{'the sum of the left-bottom quarter of C is '}\NormalTok{, sum_unwanted(knn))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
With parameter  1 the sum of the left-bottom quarter of C is  10
With parameter  2 the sum of the left-bottom quarter of C is  17
With parameter  3 the sum of the left-bottom quarter of C is  15
With parameter  4 the sum of the left-bottom quarter of C is  14
With parameter  5 the sum of the left-bottom quarter of C is  13
\end{verbatim}

\hypertarget{linearsvc}{%
\subsubsection{LinearSVC}\label{linearsvc}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ use_svc(alpha, balanced}\OperatorTok{=}\VariableTok{False}\NormalTok{,linear}\OperatorTok{=}\VariableTok{True}\NormalTok{):}
    \CommentTok{#define the model}
    \ControlFlowTok{if}\NormalTok{ linear:}
\NormalTok{         model }\OperatorTok{=}\NormalTok{ LinearSVC(max_iter}\OperatorTok{=}\DecValTok{5000}\NormalTok{)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{         model }\OperatorTok{=}\NormalTok{  SVC(max_iter}\OperatorTok{=}\DecValTok{5000}\NormalTok{)}
    \CommentTok{#define the scorer}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ balanced:}
\NormalTok{        scorer }\OperatorTok{=}\NormalTok{ make_scorer(accuracy_2, alpha}\OperatorTok{=}\NormalTok{alpha)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        scorer }\OperatorTok{=}\NormalTok{ make_scorer(balanced_accuracy_2, alpha}\OperatorTok{=}\NormalTok{alpha)  }
        
\NormalTok{    pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{'scaler'}\NormalTok{, MaxAbsScaler()), (}\StringTok{'svc'}\NormalTok{, model)])}
\NormalTok{    parameters }\OperatorTok{=}\NormalTok{ \{}\StringTok{'svc__C'}\NormalTok{: np.logspace(}\OperatorTok{-}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{17}\NormalTok{, base}\OperatorTok{=}\DecValTok{2}\NormalTok{)\} }\CommentTok{# defining parameter space}
\NormalTok{    clf }\OperatorTok{=}\NormalTok{ GridSearchCV(pipe, parameters, cv}\OperatorTok{=}\DecValTok{3}\NormalTok{, scoring}\OperatorTok{=}\NormalTok{scorer)}
\NormalTok{    clf.fit(X_train, y_train)}
    \ControlFlowTok{return}\NormalTok{(clf)}
\end{Highlighting}
\end{Shaded}

Example of the LinearSVC model with a balanced\_accuracy function. With \(\alpha = 1\) the results are obviously the same as previously that is to say :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf8_alpha1 }\OperatorTok{=}\NormalTok{ use_svc(alpha}\OperatorTok{=}\DecValTok{1}\NormalTok{, balanced}\OperatorTok{=}\VariableTok{True}\NormalTok{,linear}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{evaluation_model(clf8_alpha1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Returned hyperparameter: {'svc__C': 0.015625}
Best classification accuracy2 in train is: 0.8612334093654243
Classification accuracy2 on test is: 0.8256270083284148
Confusion matrix: 
 [[22  0  0  0  0  0  0  0  0  0]
 [ 0 24  0  0  0  0  0  0  2  0]
 [ 0  0 14  1  1  0  0  0  0  0]
 [ 0  0  0 18  0  3  0  0  1  1]
 [ 0  1  0  0 17  0  0  0  0  2]
 [ 1  0  0  1  0  6  0  1  0  1]
 [ 1  2  1  0  0  0 20  0  0  0]
 [ 0  0  0  0  1  0  0 15  0  0]
 [ 0  2  0  1  0  3  0  0 11  0]
 [ 0  0  0  0  2  0  0  2  1 21]]
\end{verbatim}

We can notice that, here, the parameter of the initial model \texttt{C=0.015625}is not the one which minimizes the sum of the bottom left quarter of the confusion matrix. The minimum is \(13\) for \texttt{C=0.125}.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ np.logspace(}\OperatorTok{-}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{17}\NormalTok{, base}\OperatorTok{=}\DecValTok{2}\NormalTok{):}
\NormalTok{    model }\OperatorTok{=}\NormalTok{ LinearSVC(max_iter}\OperatorTok{=}\DecValTok{5000}\NormalTok{,C}\OperatorTok{=}\NormalTok{c)}
\NormalTok{    pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{'scaler'}\NormalTok{, MaxAbsScaler()), (}\StringTok{'svc'}\NormalTok{, model)])}
\NormalTok{    pipe.fit(X_train, y_train)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'With parameter '}\NormalTok{,c, }\StringTok{'the sum of the left-bottom quarter of C is '}\NormalTok{, sum_unwanted(pipe))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
With parameter  0.00390625 the sum of the left-bottom quarter of C is  18
With parameter  0.0078125 the sum of the left-bottom quarter of C is  17
With parameter  0.015625 the sum of the left-bottom quarter of C is  17
With parameter  0.03125 the sum of the left-bottom quarter of C is  14
With parameter  0.0625 the sum of the left-bottom quarter of C is  15
With parameter  0.125 the sum of the left-bottom quarter of C is  13
With parameter  0.25 the sum of the left-bottom quarter of C is  14
With parameter  0.5 the sum of the left-bottom quarter of C is  15
With parameter  1.0 the sum of the left-bottom quarter of C is  14
With parameter  2.0 the sum of the left-bottom quarter of C is  16
With parameter  4.0 the sum of the left-bottom quarter of C is  16
With parameter  8.0 the sum of the left-bottom quarter of C is  16
With parameter  16.0 the sum of the left-bottom quarter of C is  16


C:\Users\Kim Antunez\Anaconda3\lib\site-packages\sklearn\svm\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  "the number of iterations.", ConvergenceWarning)


With parameter  32.0 the sum of the left-bottom quarter of C is  16


C:\Users\Kim Antunez\Anaconda3\lib\site-packages\sklearn\svm\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  "the number of iterations.", ConvergenceWarning)


With parameter  64.0 the sum of the left-bottom quarter of C is  16
With parameter  128.0 the sum of the left-bottom quarter of C is  16
With parameter  256.0 the sum of the left-bottom quarter of C is  16


C:\Users\Kim Antunez\Anaconda3\lib\site-packages\sklearn\svm\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.
  "the number of iterations.", ConvergenceWarning)
\end{verbatim}

With \(\alpha = 1000\), we get the expected result because the best model is now the one with \texttt{C=0.125} and the confusion matrix did changed in the good way.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf8_alpha1000 }\OperatorTok{=}\NormalTok{ use_svc(alpha}\OperatorTok{=}\DecValTok{1000}\NormalTok{, balanced}\OperatorTok{=}\VariableTok{True}\NormalTok{,linear}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{evaluation_model(clf8_alpha10)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Returned hyperparameter: {'svc__C': 0.015625}
Best classification accuracy2 in train is: 0.9484628402030914
Classification accuracy2 on test is: 0.9211322709685881
Confusion matrix: 
 [[22  0  0  0  0  0  0  0  0  0]
 [ 0 24  0  0  0  0  0  0  2  0]
 [ 0  0 14  1  1  0  0  0  0  0]
 [ 0  0  0 18  0  3  0  0  1  1]
 [ 0  1  0  0 17  0  0  0  0  2]
 [ 1  0  0  1  0  6  0  1  0  1]
 [ 1  2  1  0  0  0 20  0  0  0]
 [ 0  0  0  0  1  0  0 15  0  0]
 [ 0  2  0  1  0  3  0  0 11  0]
 [ 0  0  0  0  2  0  0  2  1 21]]
\end{verbatim}

\hypertarget{logistic-regression}{%
\subsubsection{Logistic regression}\label{logistic-regression}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{def}\NormalTok{ use_logistic(alpha, balanced}\OperatorTok{=}\VariableTok{False}\NormalTok{):}
    \CommentTok{#define the scorer}
    \ControlFlowTok{if} \KeywordTok{not}\NormalTok{ balanced:}
\NormalTok{        scorer }\OperatorTok{=}\NormalTok{ make_scorer(accuracy_2, alpha}\OperatorTok{=}\NormalTok{alpha)}
    \ControlFlowTok{else}\NormalTok{:}
\NormalTok{        scorer }\OperatorTok{=}\NormalTok{ make_scorer(balanced_accuracy_2, alpha}\OperatorTok{=}\NormalTok{alpha)  }
\NormalTok{    pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{'scaler'}\NormalTok{, StandardScaler()), (}\StringTok{'logreg'}\NormalTok{, LogisticRegression(max_iter}\OperatorTok{=}\DecValTok{5000}\NormalTok{))])}
\NormalTok{    parameters }\OperatorTok{=}\NormalTok{ \{}\StringTok{'logreg__C'}\NormalTok{: np.logspace(}\OperatorTok{-}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{17}\NormalTok{, base}\OperatorTok{=}\DecValTok{2}\NormalTok{)\} }\CommentTok{# defining parameter space}
\NormalTok{    clf }\OperatorTok{=}\NormalTok{ GridSearchCV(pipe, parameters, cv}\OperatorTok{=}\DecValTok{3}\NormalTok{, scoring}\OperatorTok{=}\NormalTok{scorer)}
\NormalTok{    clf.fit(X_train, y_train)}
    \ControlFlowTok{return}\NormalTok{(clf)}
\end{Highlighting}
\end{Shaded}

Example of the LogisticRegression model with a accuracy function. First, with \(\alpha = 1\) :

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{clf9_alpha1 }\OperatorTok{=}\NormalTok{ use_logistic(alpha}\OperatorTok{=}\DecValTok{1}\NormalTok{, balanced}\OperatorTok{=}\VariableTok{True}\NormalTok{)}
\NormalTok{evaluation_model(clf9_alpha1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Returned hyperparameter: {'logreg__C': 0.0078125}
Best classification accuracy2 in train is: 0.8692423758419983
Classification accuracy2 on test is: 0.8337791822414583
Confusion matrix: 
 [[22  0  0  0  0  0  0  0  0  0]
 [ 0 21  0  3  0  0  0  0  2  0]
 [ 0  0 13  1  1  0  1  0  0  0]
 [ 0  0  1 17  0  3  0  0  1  1]
 [ 0  1  0  0 18  0  0  0  0  1]
 [ 1  0  0  0  0  8  0  1  0  0]
 [ 1  1  1  0  0  0 20  0  1  0]
 [ 0  0  0  0  1  0  0 14  0  1]
 [ 0  2  0  1  0  3  0  0 11  0]
 [ 0  0  0  0  0  0  0  2  0 24]]
\end{verbatim}

We can notice that, here, the parameter of the initial model \texttt{0.0078125} already the one which minimizes the sum of the bottom left quarter of the confusion matrix. The minimum is also the same (\(13\)) for \texttt{C=0.00390625} and \texttt{C=0.25}.

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{for}\NormalTok{ c }\KeywordTok{in}\NormalTok{ np.logspace(}\OperatorTok{-}\DecValTok{8}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{17}\NormalTok{, base}\OperatorTok{=}\DecValTok{2}\NormalTok{):}
\NormalTok{    pipe }\OperatorTok{=}\NormalTok{ Pipeline([(}\StringTok{'scaler'}\NormalTok{, StandardScaler()), (}\StringTok{'logreg'}\NormalTok{, LogisticRegression(max_iter}\OperatorTok{=}\DecValTok{5000}\NormalTok{,C }\OperatorTok{=}\NormalTok{ c))])}
\NormalTok{    pipe.fit(X_train, y_train)}
    \BuiltInTok{print}\NormalTok{(}\StringTok{'With parameter '}\NormalTok{,c, }\StringTok{'the sum of the left-bottom quarter of C is '}\NormalTok{, sum_unwanted(pipe))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
With parameter  0.00390625 the sum of the left-bottom quarter of C is  13
With parameter  0.0078125 the sum of the left-bottom quarter of C is  13
With parameter  0.015625 the sum of the left-bottom quarter of C is  16
With parameter  0.03125 the sum of the left-bottom quarter of C is  15
With parameter  0.0625 the sum of the left-bottom quarter of C is  14
With parameter  0.125 the sum of the left-bottom quarter of C is  14
With parameter  0.25 the sum of the left-bottom quarter of C is  13
With parameter  0.5 the sum of the left-bottom quarter of C is  14
With parameter  1.0 the sum of the left-bottom quarter of C is  14
With parameter  2.0 the sum of the left-bottom quarter of C is  14
With parameter  4.0 the sum of the left-bottom quarter of C is  15
With parameter  8.0 the sum of the left-bottom quarter of C is  15
With parameter  16.0 the sum of the left-bottom quarter of C is  15
With parameter  32.0 the sum of the left-bottom quarter of C is  15
With parameter  64.0 the sum of the left-bottom quarter of C is  15
With parameter  128.0 the sum of the left-bottom quarter of C is  15
With parameter  256.0 the sum of the left-bottom quarter of C is  15
\end{verbatim}

\end{document}
