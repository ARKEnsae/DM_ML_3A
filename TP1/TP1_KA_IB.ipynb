{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**NAMES :  Kim ANTUNEZ, Isabelle BERNARD (Group : Mr Denis)**\n",
    "\n",
    "<h1><center> TP1 : Basic functions for Supervised Machine Learning. </center></h1>\n",
    "\n",
    "The deadline for report submission is Tuesday, November 10th 2020.\n",
    "\n",
    "Note: the goal of this first TP is to become familiar with 'sklearn' class in Python. In particular, we introduce most popular supervised learning algorithms. \n",
    "\n",
    "PART 1 is a list of commands that should be followed step by step. PART 2 is an open problem for which we are waiting for your creativity!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imported packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import MaxAbsScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, make_scorer, confusion_matrix\n",
    "\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1) #to fix random and have the same results for both of us "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  PART 1 -- MNIST\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first part of TP1 we pursue the following goals:\n",
    "1. Apply standard ML algorithms on a standard benchmark data\n",
    "2. Learn basic means of data visualizations\n",
    "3. Get familiar with sklearn's GridSearchCV and Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST dataset consists of black and white images of hand-written digits from $0$ to $9$ of size $28 \\times 28$.\n",
    "In this exercise we will work with a small from the original MNIST dataset. \n",
    "\n",
    "If you are interested in the whole dataset, execute the following commands\n",
    "```python\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home=custom_data_home)\n",
    "```\n",
    "\n",
    "Hence, the observations $(X_1, Y_1), \\ldots, (X_n, Y_n)$ are such that $X_i \\in \\mathbb{R}^{784}$ and $Y_i \\in \\{0, \\ldots, 9\\}$. To be more precise, each component of vector $X_i$ is a number between $0$ and $255$, which signifies the intensity of black color.\n",
    "\n",
    "The initial goal is to build a classifier $\\hat g$, which receives a new image $X$ and outputs the number that is present on the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data contains: 2000 samples of dimension 784\n",
      "Test data contains: 200 samples\n"
     ]
    }
   ],
   "source": [
    "X_train = np.load('data/mnist1_features_train.npy', allow_pickle=True)\n",
    "y_train = np.load('data/mnist1_labels_train.npy', allow_pickle=True)\n",
    "X_test = np.load('data/mnist1_features_test.npy', allow_pickle=True)\n",
    "y_test = np.load('data/mnist1_labels_test.npy', allow_pickle=True)\n",
    "\n",
    "n_samples, n_features = X_train.shape # extract dimensions of the design matrix\n",
    "print('Train data contains: {} samples of dimension {}'.format(n_samples, n_features))\n",
    "print('Test data contains: {} samples'.format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each observation is actually an image, we can visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAAA6CAYAAAATDorhAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAXA0lEQVR4nO2de1RU173Hv3sCOF7ehOdFkBgUsnxEjdF6IRq7xJREtLpsDCsVxRqFlZBeWNFCJUEvCyW1pBUaq7FVE7KsETVQrxqX8ZFyJT4SNNIbCRglUYwSKAIKKsr3/gFzLiMzw5k3bfZnrb3EmTnnfNj77N/s8zv7bARJSCQSicQxaJwtIJFIJD8kZNCVSCQSByKDrkQikTgQGXQlEonEgcigK5FIJA5EBl2JRCJxIDLoSiQSiQOxadAVQkQIIfYLIZqFENeEEH8QQrjY8hgqPd4XQnwnhGgVQtQIIZY42uEBnxeEEOeFELeEEF8LIZ5ygoPT60QIcfOBcl8IUSQ9nOvR4+L086PH45gQ4navOvnKCQ72bReSNisA9gPYBkALIBhAFYBXbXkMlR4jAQzq+TkawDUATzjao+f4cQC+AfAjdH/JhQII/SHXSY+DO4CbAKY4y0F6DLzzA8AxAEuc2Rb2bhdbpxceAbCT5G2S1wB81NOYDoXk/5K8o/tvT3nU0R49rAbwXyRPkOwiWU+y3tESA6xOAGAegAYA5U50kB49DMDzY6Bg83axddBdD+AFIcS/CSFCAcSjO/A6HCHEBiFEO4BqAN+hexTuaIeHAEwAECCEuCCEuNKTchnsaJceH6fXSS8WAniPPcMJ6eF8jwF0fqwVQjQKIY4LIZ52koMO27eLjYfijwH4HMA9dH9TbgMgnHhp8BCAWADZAFydcPx/76mHzwCEAPAHcBxA3g+1TnocwgHcB/CIs+pBegzM8wPAJACeAAb1BLw2AI/+K7WLzUa6QggNgIMA9qA7D+IPwBfAm7Y6hrmQvE/yfwAMAZDqBIWOnn+LSH5HshHAWwCedYILgAFRJwCQBOB/SF5y0vGlhxGcfX6QPEmyjeQdku+ie5DirP5il3axZXrBD0AYgD/0VFgTgK1wYoDphQuckJ8i2QzgCrpHuwMNp9RJD0kA3nXSsXsjPYzjzPOjNwQgnHRsu7SLzYJuzyjuEoBUIYSLEMIH3ZcHX9jqGGoQQgT2TNHyEEI8JIR4BkAigCOO9OjFVgBpPV6+AP4TwH87UmAg1YkQ4j/QPYOjxNHHlh5GHQbE+SGE8BFCPCOE0PbEkBcBTEH3FbRDsWu72DgHMhbdUz6aATT2CAc6OA8TAOATADcAtKJ72tpLzsgJ9fi4AtjQ43MNQCEA7Q+1TgBsAlDsrPaQHgP3/OjxOI3uPO4NACcAxP2rtYvoOYBEIpFIHIB8DFgikUgciAy6EolE4kBk0JVIJBIHIoOuRCKROJD+VgBzxl02Q3PypIc+0kMf6dGXgeIiPR5AjnQlEonEgcigK5FIJA5EBl0HUllZiYcffhhCCOzdu9fZOhKJxAn093DEQMmD/FN7dHR0r3szZcoUfP755wAAT09PtLS0ONTDSqSHPgPZAxg4Lqo9GhsbAQD+/v64fPkyAKCpqQkAUFZWhry8PEyfPh1FRUV49FGTy0IM6Lax6Z/S6erqQl1dnd5rw4YNU37+9a9/jbVr12LPnj2YNWsWHnroIVseHh0dHTh48CBWr16Ns2fP9nl/y5Yt8PX1BQBERkZi1KhRNj2+MXSBVvcvAAQHBzvk2BKgtLQU+fn5OHnypPLa8OHDsWRJ91+k8fT0RGqqYxbUOnfuHFatWgUA+OUvf4kJEybA3d3dIccGuvvoxYsXkZubi4qKCsyfP1/v/SlTpgAAJk+eDK1WC1dXV4e5JSQk4Pr16wgKCsLFixcBAA0NDXqfOXDgAN577z2sXr3aYV62xiYj3ZaWFqxYsQL19fXYv19/3ePCwkK88sorqK+vR1xcHKqrqwEAmzdvxi9+8QuDTmo9vvrqK7z55v+vHNne3o6dO3eqUcaoUaOwa9cujBgxwthHbPZtmZaWBgB4++23AQBDhw7F4cOH9b6QTGCVx71791BdXY2///3vuHLlCgCgtbUVJSUlqK6uhr+/Pw4fPowxY8bY1UNHXV0djh49CgDIz89HTU2N3vtz587F+++/j8GDja7zbpbHt99+i7i4uD7H6Y1Go8GiRYsQGxuLn//852oDjUX1sWnTJqSmpiIpKQlubm44dOgQxo0bBwBwdXXF1KlTAQBDhgzB1KlT4e3tbYmHUZcNGzYo56PBjXrigRAC06dPx9SpU7Fs2TI8/PDD/XkYc+m3TpqampCfn4+CggIYikfh4eFobm5GZGQksrOzkZCQ0F8bWXyubtq0CQ0NDVi0aBGOHTuGiooKAMDGjRsBAD4+PsjIyMCzzz6LJ554or/dGW6bfhZn6JdTp04xPj6eQgiDxc3NjUePHuXmzZv1Xt++fbuxXar2CAsLM3pcNcXLy4tpaWlWe5hi79699PHxoY+Pj3Lc9PR0c3ZhtkdXVxerqqqYk5NDPz8/CiEYGBjIBQsWcMGCBXzllVe4Z88ezpo1ixqNhn/961/t4tHZ2cnvv/+eGRkZjI6OZnR0NP39/enr60tfX1/OmTOHmZmZPHToEHNychgWFkYAzMvLs6nH5cuXef78eaPlxIkTjIiIIAAuXLiQp0+ftkt96PD39+c777yj/P/KlSu8cuUKKyoqmJOTwxUrVjAhIYFBQUHcuXOnJR4GXZqbmxkVFUWNRsOwsDDGx8dz69at3Lp1K8eNG8eoqChGRkYyMjKSGo1GKSEhITxx4oSaX82iOnnxxRd1fx6IAQEBXLVqFT/++GOltLa2sqqqSs2uLPaoqqpiUlISNRqNErd0Pxsq3t7e/OyzzyzxsD7opqenUwhBrVbL119/nSdPnuStW7d469YtlpeXMy8vj2PHjqVWq1WEU1NTefPmTXNEDfLaa6/pVYSPjw/feustRkdHqw68o0ePNtagNgm6Cxcu7HPM4uJic3Zhlkd7ezuzsrKUQPvyyy/zyJEjep+5ffs209PTGRISwm3bttnFgyTPnz9PIQQBUAjB+fPns6ysjE1NTWxqaurz+djYWALgoUOHbOqhht/+9rdKx582bRrb2tr628SqoDtjxgyTn9mwYQMB8PHHH7fEw6BLR0cHf/zjH9PDw4PHjx83uLPOzk52dnaypKSEycnJ9PPzo0ajYWhoKC9dumSJi0mqqqo4ePBg5Rx54403+ttEDao9kpOT6eXlpRefepfg4GAGBwczPT2d6enpXLx4sfLe+vXrLfGwPuh6eHhQCMHExESjn5k1a5YiOmXKFDY2NporapDq6mp+/fXXSvnmm29IknV1dXz55ZeV18ePH09/f3+Dlern58ejR49a5WGM+vp6urm56R1vw4YN7OrqMmc3qj1qamoYFxdHPz8/FhQU9Hn/8uXLvHz5MhMSEhgbG2v30UNTUxN/85vfKKW2ttboZ2tqajho0CCmpaXx3r17NvVQwzvvvKMEXQA8efJkf5tY7LF06VK6ubmZ/MzPfvYzAuCsWbMs8TDqsnbtWi5ZskStKnft2qWMeM+cOWOJi0kWL16s1HnvGHLu3DmeO3eOBQUFXLhwIfft28e7d++q1Vbl8cc//lFvNDt8+HCmpqYyNTWVZ86cYWNjI2/cuMEbN24o21y8eHHgBN2YmBh2dHT0ef/IkSP09fVVAlw/AdeYqEHUjhgvXLjAH/3oR30Crru7O/fs2WO1hyG6urq4bNkyveNptVrW1NSYsxvVHu3t7YyLi+Ps2bP71PG9e/e4b98+BgUFMSgoiGvWrOGtW7fs4mEpuroqLy93iserr76qF3RXrFhhVw9T/eDatWvUarUEwPfee88SD5u1TWVlpd2CbnV1tfJ7AuDTTz/NNWvWMDExkR4eHvTw8NBrk7CwMKamptoshiQkJHDBggV8++23+dprr6nqmyUlJUpf7ueKzJiH7dILQgjW19frvXf37l0OHjxYyZHYK3fYm5s3b/LixYt88sknlRIVFWUwn2sir2y1x507d/ocMzk52ZxdmOVx+vRpxsTE9Dkh29rauGLFCoaEhHDfvn3ct2+fJQ6qPczl7t27zM/PJwDOmzfPKR43btzgxIkT9Tr4mjVrHO6ho7S0lADo7+/P+/fvW+JhE5dTp05xzpw5dksvjBkzRq/O1RYVI3VVHi0tLf1dVelx4cIFenp6UgjBgIAANZvYJ+h+8sknyk2iiRMn6uXqXn/9dSVXk5WVpfZ3s/gEunnzJl944YV+87g+Pj7cvXu33TyuXr3KtWvXKscbOXIkR44cqdTNiRMnWF5ezlOnTqnZncUex48f54QJExgfH8+6ujq1m9ncwxRHjhyhEIJDhgxR62gzj4aGBjY0NHD16tV9OraK3KJd6uPq1at85JFHCIBz585Vs4nNgu7Zs2e5ceNGbty4kSNGjKCPj49yI01FusWYi1F0uVxd0Wq1fOyxx+jm5qaUxMRElpeX8+OPP+aXX37JqVOn0sXFhevWrTOVprNL2+hGuUIITps2Tc0m9gm6JLly5UpFJi0tjWVlZSwrK1MqNTAw0JxOb7HHlStXVN0827p1q109ioqK9I6nC7oFBQXMyMjgoEGDrL1EMcm9e/f4xhtv0NfXl1lZWfz000/55ptvKmX69OmcNGkSJ02axKVLlyqv6+4U27o+jNHY2MiYmBgKIVhZWal2M5t5VFZWsrKysk/Afe6553jnzh2HefSmsLCQABgdHa3mMtqYh1GX5uZmFhYW6pUlS5YwJCSE3t7eyjmrSynMnDlT7WwOYy5G6R10vb29+9zwNYTuKgAAN2/ebBMPNZSWliqDy6efftqqtrFJ0O3o6GBycrLeSFInCMCud+t709TUxIkTJ/YbdIODg9V0cos9UlJSVM+emD59uk097t+/z6KiIgKgm5sbw8LC6Ofnx6ioKKWkpaVx5cqVSomPj2dUVBSHDBnCiIgIfvTRR4ZGETY7kZubm9nc3MxVq1bR1dWV69atU3MZbVOPiooKzpw5kzNnzuwTdFVeldm8Y1dVVdHNzY0ADN4INcPDqEtKSoredLAHS++gu3HjRnZ2dprzK5hVJ59//jlzcnI4Y8YM1fc6kpKSlHaKj4+3iYcaZs+erdTNli1b1G5msG3k2gsSiUTiSIxFY0u+HQIDA/VGDN7e3uZcNpr6dlBNbW0td+zYoVd0l/O9y/Lly+3mER4ernqk+6c//clmHl988QUXLVpEAPTz8+Ps2bNZXFzMq1evqvJubW3ln//8Z7q6unL//v0We/RHZmYmMzMzCcCSm4tWe1RVVTEqKsrgTZply5axvb3dIR462tvb2d7ezrlz5yrzhM2YVmhW301NTe0zjbF30dWDbrbR+vXr2draqvaGk0V1ovYq586dO3zqqacUx4yMDJt6GKKlpYUtLS1KGiw0NJTXr19Xu7n90gtk9/StBycYq7wRoEbUKm7fvt1n+parq2t/05Ms8vjLX/6iOuD6+PiomSur2qO4uJhBQUFmBdoH2bNnD11dXXnu3DmLPUyxefNmpdPExMRYsgurPHbs2NHnBo6ueHl5qXkowiYevSkqKlJSQj4+Pmqf/jLlYdJl//79yjEfLAUFBSwoKGBoaCg9PDyUtENmZqaaebI277u9SUtL02uvv/3tbzb3aGxsZHl5uVISExOZmJio9NnBgwezsLCQ3333nZrd2S/oXr9+ncOGDTMYWCzALg3Xe5aFrtgj6G7fvl110B06dKiaXar2aGlp4bVr19Ts0yC7d+/mmDFj+Pzzz9slp1tTU8PQ0FCOHTuWY8eOVXMT0RAWeXR1dbG0tJQajcZgwNVqtfz000/t7vEgp0+fpouLC11cXAiA69atM3cXVg+YjFFeXs78/HwOHTqUGo2GWVlZ/d1gtIvHnTt3+gTcadOmmRp9m+3R2NjILVu2cPz48f3227Fjx/Lbb79Vo26foNvW1sa8vDxFyN3d3ZzAplbUai5dusTAwEDFKzU11S4nkNqgq9VqWVZWpmaXdh096Lh48SKDg4MZGxur9wSOLT3S0tLo7e3NgwcP8uDBg5aqWuTR0tJicu5nYWGhQzwedAoKClIcJk+ebO7TisY8bHqOVFZW0svLixqNpr8vBYs82tvbjY4c6+rqlKsAXYmKiuKOHTts6tF7IoCxEhERwdzcXOXJVxXYJ+j2lo2IiGB5eTnDw8OVvObvf/97tYKmRK2ipqaGEyZMcEhOd86cOaqC7urVq9Xq2z3o7t69m/7+/qYCrtUeubm51Gq1lgQ3qz22b99OT0/PPoE2ICCAAQEB/NWvfqVmipjVHr25f/8+4+LiCEBZZMaM1EZ/HjY/R1588UVqNBqGh4fzH//4hzkuJmlububatWv50UcfKa81NTXxgw8+4AcffMCf/vSnfdqtnwWRLPKoq6tjSkoKS0pKlDJ69Gi9PltSUtLfbtR4WB90ey8A8e677zI7O1tP1MANGUtE9Th8+DBHjRqllPLyctbW1rK2tpYNDQ2sr69nbW0tU1JSmJKSwoiICIfdSJs/f76qgGvljRKbkZeXRw8PD6alpZkKuFZ57Nq1i+7u7nzppZfMeX7eZh5z5swxOLpNSkpiUlKSwzx6s2PHDgJgcHAwz5w5o+YRW3M8bB50i4qKlPyuiRSWao/6+nru2rWLgYGBjI2N5ffff8+9e/dy7ty59PLyMthew4cP51tvvaXmRqfV9dHe3s7JkyfrpRTMGOGa8rA+6AYEBFAIwVGjRrG+vp5PPvmk3XO6H374odGAFhsb2+8qY8nJyWoeSbaoPlpbW00udfn888+zpaXFpvVhCbW1tZwxYwb9/PyYn59v6eOmqtDdpPrmm2+syjlb4lFVVUVfX1+9zhsUFMQPP/ywz2Im9vTozeXLlzlo0CBqNBpzVnkzx0OVy9WrVxkfH89NmzYZXDfl1KlT3LlzJ+fNm6ekF4YNG8bm5mZzXAyybds2pT1cXFwYEhJiNPXj5+fHjIwMc84dq/tMaWmpXr9VmQpU42F90NUteBMZGamss6ArplYeM1NUD1NB11Tx9fWlv78/z58/bxMPY9y+fZt79+5lWloaAwIClClSmZmZ5kw3sdrjQdra2tjW1sacnBxqtVpGR0ebk3M326Ozs5MrV65UHqv93e9+Z0mO3yqPpUuX9unAx44ds9bBbA8dLS0tDA0NJQDOnj3bXh6qXPbv36+MXocNG8YRI0Zw+PDhHD58uN5jwL0/U11dba6LQS5cuMDw8HCjgVaXcpk8eTJzc3NVVoX5HoZobm7mpEmTKIRQHkc+cOCAuQ7GPKwPuklJSX2CW0xMDGNiYtTOd1QjqkdlZSUXL15sdA3MB8uiRYu4ePFiU9/QFnk4CKs9bt26xSVLltDd3Z3u7u6Mjo5mcXGxuXlMsz16r6er1WotyYlZ7REfH690ZA8PD1ZUVNjCwWwPHY8//jgBUKPRqFlAxlIPVS63b99mcnKy0SfSdCUsLIzr169X03/M8vjyyy85ZcoUpqam8rnnniMAhoSE8NixY0bXXFaJxX3m7t27HDduHIXonlaam5trSdA35WF90N25c6fSUG5ubszNzeW1a9esuYxU7bFu3TqjOVPd+g9lZWVmrSRkiYedMdvjwIEDHDlyJIuLi1lbW8tnnnmGnp6ezMrKYlZWlqUns9keujSLu7u7mr+AYBeP+vp6jh49mnPnzrVlwDXbQ8e8efMIwJrZG2o8VJ+rnZ2dPH78OLOzs5mdnc3ly5dz+fLl/MlPfsLs7Gx+9tln5gye/mn7jI7eaYWnnnrKHh62fSLNRkgPKz26urp4+PBhZRQzfvx4nj171uEeeXl5jI6ONvSghUM97MRA9hhILv9UHo4IuvJPsBtHeugjPfQZyB7AwHGRHg8gF7yRSCQSB9LfSFcikUgkNkSOdCUSicSByKArkUgkDkQGXYlEInEgMuhKJBKJA5FBVyKRSByIDLoSiUTiQP4PfOHKi19gVqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = plt.subplots(1, 10)[1]  # creates a grid of 10 plots\n",
    "\n",
    "# More details about zip() function here \n",
    "# https://docs.python.org/3.3/library/functions.html#zip\n",
    "images_and_labels = list(zip(X_train, y_train)) \n",
    "for ax, (image, label) in zip(axes, images_and_labels[:10]):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    ax.set_title('{}'.format(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 0s in the train dataset is 196\n",
      "Number of 1s in the train dataset is 226\n",
      "Number of 2s in the train dataset is 214\n",
      "Number of 3s in the train dataset is 211\n",
      "Number of 4s in the train dataset is 187\n",
      "Number of 5s in the train dataset is 179\n",
      "Number of 6s in the train dataset is 175\n",
      "Number of 7s in the train dataset is 225\n",
      "Number of 8s in the train dataset is 186\n",
      "Number of 9s in the train dataset is 201\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Number of {}s in the train dataset is {}'.format(i, np.sum([y_train == str(i)])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we conclude that the dataset is rather balanced, that is, each class contains similar amount of observations. The rarest class is $y = 6$ with $175$ examples and the most common class is $y = 1$ with $226$ examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question:** Explain in your report what happens when we run \n",
    "```python\n",
    "clf.fit(X_train, y_train)\n",
    "```\n",
    "What is the complexity for each of the three following cases? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :**  \n",
    "\n",
    "The general objective here is to obtain a first classifier with the **KNN method**. To do that, we test different parameters of the KNN methods and choose the bests using a **cross validation**. That is to say that we test the KNN method by varying the number of neighbors from 1 to 5. The cross validation method used is called **the 3-fold Cross Validation** (CV) following those different steps:\n",
    "\n",
    "1. we divide our training sample into 3 training sub-samples\n",
    "2. we train the model on 2 samples and test it on the third one\n",
    "3. We choose the parameter which has the best average test accuracy (see definition later) on the 3 samples.\n",
    "\n",
    "\n",
    "**clf.fit(X_train, y_train)** applies what is described above to the training sample. It fits the model (learns from it) using X_train as training data and y_train as target values. The first clf (for classifier) used here is \"KNeighborsClassifier\" that is to say the k-nearest neighbors vote.\n",
    "\n",
    "\n",
    "Let's imagine that you train a model on n points and it takes x minutes. If you train it on kn points, it takes kx minutes if the training time is linear, but sometimes it is more. For example, if it takes k2x, the training time is quadratic in the number of points. That is what we call the **complexity** of an algorithm. The question here is very broad (not very precise), because there are at least two different kinds of complexities : **training complexity and prediction complexity**. \n",
    "\n",
    "We define the complexity using a Big-O measure. It provides us with an asymptotic upper bound for the growth rate of the runtime of the chosen algorithm. Calling n the number of training samples and p the number of features the complexity predicted for the three methods are : \n",
    "\n",
    "* For the **knn** classifier : The parameter used for the algorithm is here ‘auto’. It selects ‘kd_tree’ if $k < N/2$ and the ‘effective_metric_’ is in the ‘VALID_METRICS’ list of ‘kd_tree’. It selects ‘ball_tree’ if k < N/2 and the ‘effective_metric_’ is not in the ‘VALID_METRICS’ list of ‘kd_tree’. It selects ‘brute’ if k >= N/2. For the brute-force method there is no training, (training complexity = $O(1)$),  but classifying has a high cost ($O(knp)$). kd-tree and ball_tree are $O(pnlog(n))$ for training and $O(klog(n))$ for prediction. \n",
    ". See precisions [here](https://towardsdatascience.com/k-nearest-neighbors-computational-complexity-502d2c440d5) and [here](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html). \n",
    "\n",
    "\n",
    "* Support Vector Machines (**SVM**) are powerful tools, but their compute and storage requirements increase rapidly with the number of training vectors. The core of an SVM is a quadratic programming problem (QP), separating support vectors from the rest of the training data. The QP solver used by the libsvm-based implementation (`SVC` function) scales between O($pn^2$) and O($pn^3$) depending on how efficiently the libsvm cache is used in practice (dataset dependent). But recent approaches like [this one](https://www.cs.huji.ac.il/~shais/papers/SSSICML08.pdf) are inverse in the size of the training set. In the case of the `LinearSVC` method used in this \"TP\", it is indicated in the [documentation](https://scikit-learn.org/stable/modules/svm.html#complexity) that the implementation is much more efficient than its libsvm-based `SVC` counterpart and it's training complexity is $O(pn)$ and prediction one remains $O(n_{sv}*p)$ with $n_{sv}$ the number of Support Vectors.\n",
    "\n",
    "\n",
    "* For **logistic regressions**, training complexity is $O(np)$ and prediction one is $O(p)$. See proof [here](https://levelup.gitconnected.com/train-test-complexity-and-space-complexity-of-logistic-regression-2cb3de762054).\n",
    "\n",
    "*Main sources : [here](https://medium.com/@paritoshkumar_5426/time-complexity-of-ml-models-4ec39fad2770) and [here](https://www.thekerneltrip.com/machine/learning/computational-complexity-learning-algorithms/)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV with kNN : a simple baseline\n",
    "knn = KNeighborsClassifier() # defining classifier\n",
    "parameters = {'n_neighbors': [1, 2, 3, 4, 5]} # defining parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GridSearchCV(knn, parameters, cv=3) #cross-validation : method 3-fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                            metric='minkowski',\n",
       "                                            metric_params=None, n_jobs=None,\n",
       "                                            n_neighbors=5, p=2,\n",
       "                                            weights='uniform'),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'n_neighbors': [1, 2, 3, 4, 5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'n_neighbors': 1}\n",
      "Best classification accuracy in train is: 0.891497944721333\n",
      "Classification accuracy on test is: 0.875\n"
     ]
    }
   ],
   "source": [
    "print('Returned hyperparameter: {}'.format(clf.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 26  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  2  0  0  0  0]\n",
      " [ 0  0  0 19  0  2  0  0  1  1]\n",
      " [ 0  1  0  0 17  0  0  0  0  2]\n",
      " [ 0  0  0  0  1  7  1  0  1  0]\n",
      " [ 0  0  0  0  0  1 23  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 15  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 14  1]\n",
      " [ 1  1  0  0  2  0  0  3  0 19]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the test accuracy? What would be the accuracy of random guess?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer :**\n",
    "\n",
    "Accuracy is the number of correctly predicted data points out of all the data points. The `accuracy_score` function computes the accuracy, either the fraction (default) or the count (`normalize=False`) of correct predictions.\n",
    "\n",
    "More formally, for a **binary problem** it is defined as the number of true positives (y predicted 1 and with a true value of 1) and true negatives (y predicted 0 and with a true value of 0) divided by the number of true positives, true negatives, false positives (y predicted 1 and with a true value of 0), and false negatives (y predicted 0 and with a true value of 1). \n",
    "\n",
    "$$\n",
    "\\texttt{accuracy} = \\frac{TP + TN}{TP + TN + FP + FN}\n",
    "$$\n",
    "\n",
    "In multilabel classification, the function returns the subset accuracy. If the entire set of predicted labels for a sample strictly match with the true set of labels, then the subset accuracy is 1; otherwise it is 0.\n",
    "\n",
    "If $\\hat{y}_i$ is the predicted value of the $i$-th sample and $y_i$ is the corresponding true value, then the fraction of correct predictions over is defined as $n_\\text{samples}$. Here is the normalized accuracy score : \n",
    "\n",
    "$$\n",
    "\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1(\\hat{y}_i = y_i)\n",
    "$$\n",
    "\n",
    "See more details [here](https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score) \n",
    "\n",
    "The accuracy is used to to determine which model is best at identifying relationships and patterns between variables in a dataset based on the input data or training data. Here we comment the \"test accuracy\" that is to say the accuracy of the test sample and not on the training sample !\n",
    "\n",
    "The test accuracy  is here **0.875**. On a **random guess it would be 0.1** : one chance to be guess the right number out of 10 possible numbers (10 classes).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy normalisée :  0.4\n",
      "accuracy non normalisée :  2\n"
     ]
    }
   ],
   "source": [
    "#Simple example of accuracy for a multiclass analysis to illustrate.\n",
    "y_true = [0, 0, 1, 2, 3]\n",
    "y_pred = [0, 1, 2, 1, 3]\n",
    "print(\"accuracy normalisée : \", accuracy_score(y_true, y_pred))\n",
    "print(\"accuracy non normalisée : \", accuracy_score(y_true, y_pred, normalize=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, \n",
    "\n",
    "$$\n",
    "\\texttt{accuracy}(y, \\hat{y}) = \\frac{1}{n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1(\\hat{y}_i = y_i) = \\frac{1}{5} \\sum_{i=0}^{4} 1(\\hat{y}_i = y_i) =  \\frac{1}{5} * 2 = 0.4\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Question:** What is ``` LinearSVC()``` classifier? Which kernel are we using? What is ```C```? (this is a tricky question, try to find the answer online)\n",
    "\n",
    "**Answer :** \n",
    "\n",
    "``` LinearSVC()``` (Linear Support Vector Classification) is a fast implementation of Support Vector Machine Classification (SVM) for the case of a linear kernel. It is similar to `SVC` with parameter `kernel=’linear’`, but implemented in terms of `liblinear` rather than `libsvm`, so it has more flexibility in the choice of penalties and loss functions and should scale better to large numbers of samples.\n",
    "\n",
    "The main characteristics of this method are : \n",
    "- the loss used is the [‘squared_hinge’](https://en.wikipedia.org/wiki/Hinge_loss) (even if it is not indicated in the [general documentation](https://scikit-learn.org/stable/modules/svm.html#linearsvc) which is strange)\n",
    "- to generate the multiclass problem, ` LinearSVC()` uses `  One-vs-All` (see example [here](http://eric.univ-lyon2.fr/~ricco/cours/slides/svm.pdf), slide 38).\n",
    "\n",
    "More precisely, given training vectors $x_i \\in \\mathbb{R}^p$, i=1,…, n, in two classes, and a vector $y \\in \\{1, -1\\}^n$ \n",
    ", our goal is to find $w \\in \\mathbb{R}^p$ and $b \\in \\mathbb{R}$ such that the prediction given by $\\text{sign} (w^T\\phi(x) + b)$ is correct for most samples.\n",
    "LinearSVC solves the following problem:\n",
    "$\\min_ {w, b} \\frac{1}{2} w^T w + C \\sum_{i=1}\\max(0, y_i (w^T \\phi(x_i) + b))$,\n",
    "where we make use of the hinge loss. This is the form that is directly optimized by LinearSVC, but unlike the dual form, this one does not involve inner products between samples, so the famous kernel trick cannot be applied. This is why only the linear kernel is supported by LinearSVC ($\\phi$ is the identity function).\n",
    "\n",
    "The **C parameter** is a regularization or penalty parameter. SVM only work properly if the data is separable. Otherwise, we will penalize the loss of this non-separability (see [here](https://scikit-learn.org/stable/modules/svm.html#svc)) measuring the distance between the misclassified points and the separating hyperplane. C represents misclassification or error term. The misclassification or error term tells the SVM optimisation how much error is bearable. This is how you can control the trade-off between decision boundary and misclassification term. \n",
    "Concretely, when C is high, we penalize a lot for misclassification, which means that we classify lots of points correctly, also there is a chance to overfit.\n",
    "\n",
    "Documentation : C is 1 by default and it’s a reasonable default choice. If you have a lot of noisy observations you should decrease it: decreasing C corresponds to more regularization. LinearSVC and LinearSVR are less sensitive to C when it becomes large, and prediction results stop improving after a certain threshold. Meanwhile, larger C values will take more time to train, sometimes up to 10 times longer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is the outcome of ```np.logspace(-8, 8, 17, base=2)```? More generally, what is the outcome of ```np.logspace(-a, b, k, base=m)```?\n",
    "\n",
    "**Answer :** \n",
    "```np.logspace(-8, 8, 17, base=2)``` returns 17 numbers spaced evenly on a log scale. The sequence starts at $2^{-8}$ and ends with $2^{8}$.\n",
    "\n",
    "```np.logspace(-a, b, k, base=m)``` returns k numbers spaced evenly on a log scale (endpoint=True by default). The parameter `base` is the logarithmic base. In linear space, the sequence starts at $m^{-a}$ and ends at $m^b$. \n",
    "\n",
    "It is equivalent to\n",
    "1. divide the interval $[-a,b]$ into $(y_i)_{i=1..k}$ $k$ equidistant points\n",
    "2. return $\\left(m^{y_i}\\right)_{i=1..k}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kim Antunez\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "C:\\Users\\Kim Antunez\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                                 fit_intercept=True, intercept_scaling=1,\n",
       "                                 loss='squared_hinge', max_iter=5000,\n",
       "                                 multi_class='ovr', penalty='l2',\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'C': array([3.90625e-03, 7.81250e-03, 1.56250e-02, 3.12500e-02, 6.25000e-02,\n",
       "       1.25000e-01, 2.50000e-01, 5.00000e-01, 1.00000e+00, 2.00000e+00,\n",
       "       4.00000e+00, 8.00000e+00, 1.60000e+01, 3.20000e+01, 6.40000e+01,\n",
       "       1.28000e+02, 2.56000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM Classifier\n",
    "svc = LinearSVC(max_iter=5000)\n",
    "parameters2 = {'C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf2 = GridSearchCV(svc, parameters2, cv=3)\n",
    "clf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'C': 0.00390625}\n",
      "Best classification accuracy in train is: 0.8095074084579332\n",
      "Classification accuracy on test is: 0.795\n"
     ]
    }
   ],
   "source": [
    "print('Returned hyperparameter: {}'.format(clf2.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf2.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf2.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** What is the meaning of the warnings? What is the parameter responsible for its appearence?\n",
    "\n",
    "**Answer**\n",
    "\n",
    "Warnings are about the fact that the algorithm does not converge considering the maximum number of iterations given. The maximum number of iterations is given by the parameter `max_iter` which is here set to `max_iter=5000`.\n",
    "\n",
    "In fact, there is no preprocessing (date are not normalize/standardized data). Therefore unscaled data can slow down or even prevent the convergence of many metric-based and gradient-based estimators. Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler', MaxAbsScaler(copy=True)),\n",
       "                                       ('svc',\n",
       "                                        LinearSVC(C=1.0, class_weight=None,\n",
       "                                                  dual=True, fit_intercept=True,\n",
       "                                                  intercept_scaling=1,\n",
       "                                                  loss='squared_hinge',\n",
       "                                                  max_iter=5000,\n",
       "                                                  multi_class='ovr',\n",
       "                                                  penalty='l2',\n",
       "                                                  random_state=None, tol=0.0001,\n",
       "                                                  verbose=0))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'svc__C': array([3.90625e-03, 7.81250e-03, 1.56250e-02, 3.12500e-02, 6.25000e-02,\n",
       "       1.25000e-01, 2.50000e-01, 5.00000e-01, 1.00000e+00, 2.00000e+00,\n",
       "       4.00000e+00, 8.00000e+00, 1.60000e+01, 3.20000e+01, 6.40000e+01,\n",
       "       1.28000e+02, 2.56000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVM Classifier + Pipeline\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc)])\n",
    "parameters3 = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf3 = GridSearchCV(pipe, parameters3, cv=3)\n",
    "clf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'svc__C': 0.015625}\n",
      "Best classification accuracy in train is: 0.863002432717575\n",
      "Classification accuracy on test is: 0.84\n"
     ]
    }
   ],
   "source": [
    "print('Returned hyperparameter: {}'.format(clf3.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf3.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf3.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What did we change with respect to the previous run of ```LinearSVC()```?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "A pipeline allows you to perform several operations in a row. First, we renormalize the features with `MaxAbsScaler` (using the training data), in order to put them on the same scale.\n",
    "\n",
    "This estimator scales and translates each feature individually such that the maximal absolute value of each feature in the training set will be 1. \n",
    "\n",
    "For each i-th component of each vector $(X_j)$, we probably divide by the highest value (in absolute value) that is to say $X'_{i,j}=\\frac{X_{i,j}}{X_{i_{max},j}}$ with $i_{max}= \\underset{j}{\\max}|X_{i,j}|$ .\n",
    "\n",
    "Second, we apply the same algorithm as before (svc, a LinearSVC) to fit the training data in a 3-fold CV validation (as before) to choose the best value of the C parameter which seems to be `C = 0.015625`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Explain what happens if we execute\n",
    "```python\n",
    "    pipe.fit(X_train, y_train)\n",
    "    pipe.predict(X_test, y_test)\n",
    "```\n",
    "\n",
    "**Answer:**\n",
    "`pipe.fit` works. It fits the dataset as before but not using a cross-validation but using the default `C` parameter (that is to say ...) and `max_iter=5000`. \n",
    "\n",
    "\n",
    "`pipe.predict` returns the following error : \n",
    "\n",
    "`TypeError: predict() takes 2 positional arguments but 3 were given`\n",
    "\n",
    "The function does not work here because when we do a prevision, we do not need to enter the `Y` values, we just need the `X` ones. \n",
    "\n",
    "This is why the following lines work (see below). \n",
    "```python\n",
    "    pipe.predict(X_test) #working\n",
    "    pipe.score(X_test, y_test)  #working\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler', MaxAbsScaler(copy=True)),\n",
       "                ('svc',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=5000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-ed47c41d3d19>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#not working\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "pipe.predict(X_test, y_test) #not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['4', '1', '6', '5', '3', '4', '1', '3', '3', '1', '0', '6', '3',\n",
       "       '4', '9', '7', '6', '4', '1', '6', '1', '4', '3', '8', '9', '4',\n",
       "       '7', '8', '1', '1', '5', '6', '1', '4', '0', '2', '0', '9', '9',\n",
       "       '6', '2', '4', '6', '4', '9', '8', '7', '7', '0', '9', '4', '6',\n",
       "       '9', '7', '5', '2', '2', '7', '1', '6', '5', '4', '2', '8', '9',\n",
       "       '6', '3', '2', '8', '1', '7', '0', '1', '3', '2', '0', '9', '0',\n",
       "       '0', '0', '1', '0', '8', '7', '9', '9', '2', '1', '8', '9', '3',\n",
       "       '1', '5', '1', '3', '1', '3', '0', '8', '7', '0', '6', '5', '9',\n",
       "       '4', '0', '2', '5', '6', '9', '7', '5', '6', '3', '9', '7', '9',\n",
       "       '0', '9', '3', '9', '1', '3', '1', '3', '6', '1', '3', '8', '8',\n",
       "       '2', '9', '9', '6', '2', '7', '4', '3', '9', '2', '7', '0', '8',\n",
       "       '1', '2', '3', '6', '0', '8', '1', '5', '0', '0', '3', '0', '4',\n",
       "       '3', '1', '3', '9', '0', '4', '3', '9', '4', '8', '4', '7', '3',\n",
       "       '0', '9', '5', '8', '4', '6', '6', '3', '0', '4', '7', '0', '3',\n",
       "       '1', '8', '7', '8', '0', '4', '9', '6', '7', '1', '1', '2', '2',\n",
       "       '3', '6', '6', '2', '0'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X_test) #working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.835"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)  #working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('scaler',\n",
       "                                        StandardScaler(copy=True,\n",
       "                                                       with_mean=True,\n",
       "                                                       with_std=True)),\n",
       "                                       ('logreg',\n",
       "                                        LogisticRegression(C=1.0,\n",
       "                                                           class_weight=None,\n",
       "                                                           dual=False,\n",
       "                                                           fit_intercept=True,\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=5000,\n",
       "                                                           multi_class='auto',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='lbfgs',\n",
       "                                                           tol=...\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'logreg__C': array([3.90625e-03, 7.81250e-03, 1.56250e-02, 3.12500e-02, 6.25000e-02,\n",
       "       1.25000e-01, 2.50000e-01, 5.00000e-01, 1.00000e+00, 2.00000e+00,\n",
       "       4.00000e+00, 8.00000e+00, 1.60000e+01, 3.20000e+01, 6.40000e+01,\n",
       "       1.28000e+02, 2.56000e+02])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression\n",
    "pipe = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(max_iter=5000))])\n",
    "parameters4 = {'logreg__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf4 = GridSearchCV(pipe, parameters4, cv=3)\n",
    "clf4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'logreg__C': 0.0078125}\n",
      "Best classification accuracy in train is: 0.8705039372205788\n",
      "Classification accuracy on test is: 0.84\n"
     ]
    }
   ],
   "source": [
    "print('Returned hyperparameter: {}'.format(clf4.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf4.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** what is the difference between ```StandardScaler()``` and ```MaxAbsScaler()```? What are other scaling options available in ```sklearn```?\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "- ```StandardScaler()```  : Standardize features by removing the mean and scaling to unit variance\n",
    "The standard score of a sample x is calculated as:\n",
    "\n",
    "$z = (x - u) / s$\n",
    "\n",
    "where u is the mean of the training samples or zero if with_mean=False, and s is the standard deviation of the training samples or one if with_std=False.\n",
    "\n",
    "Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean and standard deviation are then stored to be used on later data using transform.\n",
    "However, the outliers have an influence when computing the empirical mean and standard deviation which shrink the range of the feature values. StandardScaler therefore cannot guarantee balanced feature scales in the presence of outliers.\n",
    "\n",
    "- ```MaxAbsScaler()``` : see previous question for the definition. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The **differences** between these two methods are the following : \n",
    "* ```MaxAbsScaler()``` method does not shift/center the data, and thus does not destroy any sparsity, and thus can be applied to sparse CSR or CSC matrices, unlike ```StandardScaler()``` \n",
    "* ```MaxAbsScaler()``` rescales the data et such that the absolute values are mapped in the range $[0, 1]$, unlike ```StandardScaler()```\n",
    "* On positive only data, ```MaxAbsScaler()``` behaves similarly to ``MinMaxScaler``` and therefore also suffers from the presence of large outliers. \n",
    "\n",
    "\n",
    "Other scaling options available in ```sklearn```:\n",
    "1. ```MinMaxScaler()``` : rescales the data set such that all feature values are in the range $[0, 1]$ As StandardScaler, MinMaxScaler is very sensitive to the presence of outliers.\n",
    "```python\n",
    "X_std = (X - X.min(axis=0)) / (X.max(axis=0) - X.min(axis=0))\n",
    "X_scaled = X_std * (max - min) + min\n",
    "```\n",
    "2. ```RobustScaler()``` : Unlike the previous scalers, the centering and scaling statistics of this scaler are based on percentiles and are therefore not influenced by a few number of very large marginal outliers (robust to outliers).\n",
    "3. ```Normalizer()``` :  The norm of each feature must be equal to 1. We can use many norms : $L^1$, $L^2$, $L^\\infty$ ...\n",
    "\n",
    "The whole list of preprocessing methods is available [here](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** using the previous code as an example achieve test accuracy $\\geq 0.9$. You can use any method from sklearn package. Give a mathematical description of the selected method. Explain the range of considered hyperparamers.\n",
    "\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "We give here the examples of two methods but there are plenty of them. \n",
    "\n",
    "1. Example 1 : SVC Classifier (other SVM classifier but not linear)\n",
    "\n",
    "> The range of considered parameter $C$ is the same as above. \n",
    "\n",
    "Given training vectors $x_i \\in \\mathbb{R}^p$, i=1,…, n, in two classes, and a vector $y \\in \\{1, -1\\}^n$ \n",
    ", our goal is to find $w \\in \\mathbb{R}^p$ and $b \\in \\mathbb{R}$ such that the prediction given by $\\text{sign} (w^T\\phi(x) + b)$ is correct for most samples.\n",
    "SVC solves the following problem:\n",
    " \\begin{align}\\begin{aligned}\\min_ {w, b, \\zeta} \\frac{1}{2} w^T w + C \\sum_{i=1}^{n} \\zeta_i\\\\\\begin{split}\\textrm {subject to } & y_i (w^T \\phi (x_i) + b) \\geq 1 - \\zeta_i,\\\\\n",
    "& \\zeta_i \\geq 0, i=1, ..., n\\end{split}\\end{aligned}\\end{align} \n",
    "\n",
    "Intuitively, we’re trying to maximize the margin (by minimizing $||w||^2 = w^Tw$), while incurring a penalty when a sample is misclassified or within the margin boundary. Ideally, $the value y_i\n",
    "(w^T \\phi (x_i) + b)$ would be $\\geq 1$ for all samples, which indicates a perfect prediction. But problems are usually not always perfectly separable with a hyperplane, so we allow some samples to be at a distance $\\zeta_i$ from their correct margin boundary. The penalty term $C$ controls the strengh of this penalty (as seen above). \n",
    "\n",
    "The dual problem to the primal is\n",
    "\n",
    " \\begin{align}\\begin{aligned}\\min_{\\alpha} \\frac{1}{2} \\alpha^T Q \\alpha - e^T \\alpha\\\\\\begin{split}\n",
    "\\textrm {subject to } & y^T \\alpha = 0\\\\\n",
    "& 0 \\leq \\alpha_i \\leq C, i=1, ..., n\\end{split}\\end{aligned}\\end{align} \n",
    "\n",
    "where $e$ is the vector of all ones, and $Q$ is an $n$ by $n$ positive semidefinite matrix, $Q_{ij} \\equiv y_i y_j K(x_i, x_j)$, where $K(x_i, x_j) = \\phi (x_i)^T \\phi (x_j)$ is the kernel. The terms $\\alpha_i$ are called the dual coefficients, and they are upper-bounded by $C$. This dual representation highlights the fact that training vectors are implicitly mapped into a higher (maybe infinite) dimensional space by the function $\\phi$ (kernel trick).\n",
    "    \n",
    "2. Example 2 : Random forest\n",
    "\n",
    "The RandomForest algorithm  is a perturb-and-combine technique specifically designed for trees. This means a diverse set of classifiers is created by introducing randomness in the classifier construction. The prediction of the ensemble is given as the averaged prediction of the individual classifiers.\n",
    "\n",
    "As other classifiers, forest classifiers have to be fitted with two arrays: a sparse or dense array X of size [n_samples, n_features] holding the training samples, and an array Y of size [n_samples] holding the target values (class labels) for the training samples. Like decision trees, forests of trees also extend to multi-output problems (if Y is an array of size [n_samples, n_outputs]).\n",
    "\n",
    "In random forests, each tree in the ensemble is built from a sample drawn with replacement (i.e., a bootstrap sample) from the training set. Furthermore, when splitting each node during the construction of a tree, the best split is found either from all input features or a random subset of size `max_features`. The purpose of these two sources of randomness is to decrease the variance of the forest estimator. Indeed, individual decision trees typically exhibit high variance and tend to overfit. The injected randomness in forests yield decision trees with somewhat decoupled prediction errors. By taking an average of those predictions, some errors can cancel out. Random forests achieve a reduced variance by combining diverse trees, sometimes at the cost of a slight increase in bias. In practice the variance reduction is often significant hence yielding an overall better model.\n",
    "\n",
    "In contrast to the original publication, the scikit-learn implementation combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class.\n",
    "\n",
    "We can vary the range of several parameters. Here we chose to move `n_estimators`. Below the different parameters possible : \n",
    "\n",
    "    * n_estimators = number of trees in the foreset\n",
    "    * max_features = max number of features considered for splitting a node\n",
    "    * max_depth = max number of levels in each decision tree\n",
    "    * min_samples_split = min number of data points placed in a node before the node is split\n",
    "    * min_samples_leaf = min number of data points allowed in a leaf node\n",
    "    * bootstrap = method for sampling data points (with or without replacement)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'svc__C': 8.0}\n",
      "Best classification accuracy in train is: 0.9190022106064085\n",
      "Classification accuracy on test is: 0.945\n"
     ]
    }
   ],
   "source": [
    "# Example 1 : SVC Classifier (other SVM classifier but not linear)\n",
    "from sklearn.svm import SVC\n",
    "svc2 = SVC(max_iter=5000) # by default : rbf kernel\n",
    "\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc2)])\n",
    "parameters5 = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "clf5 = GridSearchCV(pipe, parameters5, cv=3)\n",
    "clf5.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf5.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf5.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf5.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "#Example 2 : Random forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV # Number of trees in random forest\n",
    "\n",
    "from pprint import pprint# Look at parameters used by our current forest\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'n_estimators': 1200}\n",
      "Best classification accuracy in train is: 0.9115044579812196\n",
      "Classification accuracy on test is: 0.93\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=10, random_state=0) # defining classifier\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "parameters = {'n_estimators': n_estimators}\n",
    "clf6 = GridSearchCV(rf, parameters, cv=3) #cross-validation : method 3-fold.\n",
    "clf6.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf6.best_params_))\n",
    "print('Best classification accuracy in train is: {}'.format(clf6.best_score_))\n",
    "print('Classification accuracy on test is: {}'.format(clf6.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ```sklearn``` methods are able to output probabilities ```predict_proba(X_test)```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question** There is a mistake in the following chunk of code. Fix it.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "The line with a mistake is the following : \n",
    "```python\n",
    "axes[1, j].bar(np.arange(10), clf4.predict_proba(image.reshape(1, -1)))  # MISTAKE !\n",
    "``` \n",
    "If we execute the code line by line we find the following error \n",
    "``` only size-1 arrays can be converted to Python scalars ```\n",
    "\n",
    "It means that the two following objects do not have the same dimensions : \n",
    "\n",
    "```python\n",
    "print(np.arange(10))\n",
    "print(clf4.predict_proba(image.reshape(1, -1)))\n",
    "```\n",
    "```\n",
    "[0 1 2 3 4 5 6 7 8 9] # 1 dimension\n",
    "[[1.19370882e-01 1.08367644e-04 7.49096695e-02 7.55611181e-01\n",
    "  2.56621514e-06 4.47842619e-02 2.03011570e-04 2.06422609e-03\n",
    "  2.94488853e-03 9.45386443e-07]] # 2 dimensions => must be 1\n",
    "```\n",
    "\n",
    "The line must be replaced by : \n",
    "\n",
    "```python\n",
    "axes[1, j].bar(np.arange(10), clf4.predict_proba(image.reshape(1, -1))[0]) # CORRECTION ! \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support. ' +\n",
       "              'Please try Chrome, Safari or Firefox ≥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            if (mpl.ratio != 1) {\n",
       "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
       "            }\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        fig.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var backingStore = this.context.backingStorePixelRatio ||\n",
       "\tthis.context.webkitBackingStorePixelRatio ||\n",
       "\tthis.context.mozBackingStorePixelRatio ||\n",
       "\tthis.context.msBackingStorePixelRatio ||\n",
       "\tthis.context.oBackingStorePixelRatio ||\n",
       "\tthis.context.backingStorePixelRatio || 1;\n",
       "\n",
       "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width * mpl.ratio);\n",
       "        canvas.attr('height', height * mpl.ratio);\n",
       "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option);\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'] / mpl.ratio;\n",
       "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
       "    var x1 = msg['x1'] / mpl.ratio;\n",
       "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width / mpl.ratio, fig.canvas.height / mpl.ratio);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x * mpl.ratio;\n",
       "    var y = canvas_pos.y * mpl.ratio;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    var width = fig.canvas.width/mpl.ratio\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var width = this.canvas.width/mpl.ratio\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>');\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<img src=\"data:image/png;base64,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\" width=\"639.4666666666667\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = plt.subplots(2, 4)[1] \n",
    "\n",
    "# More details about zip() function here https://docs.python.org/3.3/library/functions.html#zip\n",
    "y_pred = clf4.predict(X_test)\n",
    "j = 0 # Index which iterates over plots\n",
    "for true_label, pred_label, image in list(zip(y_test, y_pred, X_test)):\n",
    "    if j == 4: # We only want to look at 4 first mistakes\n",
    "        break\n",
    "    if true_label != pred_label:\n",
    "        # Plotting predicted probabilities\n",
    "        #axes[1, j].bar(np.arange(10), clf4.predict_proba(image.reshape(1, -1)))  # MISTAKE !\n",
    "        axes[1, j].bar(np.arange(10), clf4.predict_proba(image.reshape(1, -1))[0]) # CORRECTION ! \n",
    "        axes[1, j].set_xticks(np.arange(10))\n",
    "        axes[1, j].set_yticks([])\n",
    "        \n",
    "        # Plotting the image\n",
    "        axes[0, j].imshow(image.reshape((28, 28)), cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        axes[0, j].set_xticks([])\n",
    "        axes[0, j].set_yticks([])\n",
    "        axes[0, j].set_title('Predicted {}'.format(pred_label))\n",
    "        j += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the Loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It often happens that the accuracy is not the right way to evaluate the performance. ```sklearn``` has a large variety of other metrics both in classification and regression. See https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics\n",
    "\n",
    "Here we want to understand how to change the cross-validation metric with minimal effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'svc__C': 0.015625}\n",
      "Best Balanced accuracy in train is: 0.8612334093654231\n",
      "Balanced accuracy on test is: 0.825627008328415\n"
     ]
    }
   ],
   "source": [
    "# SVM Classifier + Pipeline + New score function\n",
    "\n",
    "pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', svc)])\n",
    "parameters4 = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "balanced_scorer = make_scorer(balanced_accuracy_score)\n",
    "\n",
    "clf4 = GridSearchCV(pipe, parameters3, cv=3, scoring=balanced_scorer)\n",
    "clf4.fit(X_train, y_train)\n",
    "\n",
    "print('Returned hyperparameter: {}'.format(clf4.best_params_))\n",
    "print('Best Balanced accuracy in train is: {}'.format(clf4.best_score_))\n",
    "print('Balanced accuracy on test is: {}'.format(clf4.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What is ```balanced_accuracy_score```? Write its mathematical mathematical description.\n",
    "\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "The ```balanced_accuracy_score``` function computes the balanced accuracy, which avoids inflated performance estimates on imbalanced datasets. It is the macro-average of recall scores per class or, equivalently, raw accuracy where each sample is weighted according to the inverse prevalence of its true class. Thus for balanced datasets, the score is equal to accuracy.\n",
    "\n",
    "In the *binary case*, balanced accuracy is equal to the arithmetic mean of sensitivity (true positive rate) and specificity (true negative rate), or the area under the ROC curve with binary predictions rather than scores:\n",
    "\n",
    "$$\n",
    "\\texttt{balanced-accuracy} = \\frac{1}{2}\\left( \\frac{TP}{TP + FN} + \\frac{TN}{TN + FP}\\right )\n",
    "$$\n",
    "\n",
    "If the classifier performs equally well on either class, this term reduces to the conventional accuracy (i.e., the number of correct predictions divided by the total number of predictions).\n",
    "\n",
    "In contrast, if the conventional accuracy is above chance only because the classifier takes advantage of an imbalanced test set, then the balanced accuracy, as appropriate, will drop to $\\frac{1}{n_{classes}}$\n",
    "\n",
    "The score ranges from 0 to 1, or when `adjusted=True` is used, it rescaled to the range $\\frac{1}{1-n_{classes}}$\n",
    "to 1, inclusive, with performance at random scoring 0.\n",
    "\n",
    "If $y_i$ is the true value of the $i$-th sample, and $w_i$ is the corresponding sample weight (number of observations of the $i$-th class out of the total number of observations), then we adjust the sample weight to :\n",
    "\n",
    "$$\n",
    "\\hat{w}_i = \\frac{w_i}{\\sum_j{1(y_j = y_i) w_j}}\n",
    "$$\n",
    "\n",
    "where $1(x)$ is the indicator function. Given predicted $\\hat{y}_i$ for sample $i$, balanced accuracy is defined as:\n",
    "\n",
    "$$\n",
    "balanced-accuracy(y,\\hat y,w)=\\frac{1}{\\sum \\hat w_i} \\sum_i 1_{(\\hat y_i = y_i)}\\hat w_i\n",
    "$$\n",
    "\n",
    "With `adjusted=True`, balanced accuracy reports the relative increase from $\\texttt{balanced-accuracy}(y, \\mathbf{0}, w) =\n",
    "\\frac{1}{n\\_classes}$. In the binary case, this is also known as *Youden’s J statistic*, or informedness.\n",
    "\n",
    "*Source: [here](https://scikit-learn.org/stable/modules/model_evaluation.html#balanced-accuracy-score).*\n",
    "\n",
    "\n",
    "**In a nutshell, this function allows to take into account the case when somme classes are over or under-represented (= unbalanced data).**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "balanced-accuracy :  0.375\n"
     ]
    }
   ],
   "source": [
    "#Let's go back to our simple example for a multiclass analysis to illustrate\n",
    "#and calculate the balanced-accuracy\n",
    "y_true = [0, 0, 1, 2, 3]\n",
    "y_pred = [0, 1, 2, 1, 3]\n",
    "print(\"balanced-accuracy : \", balanced_accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, \n",
    "\n",
    "$$\n",
    "balanced-accuracy(y,\\hat y,w)=\\frac{1}{\\sum \\hat w_i} \\sum_i 1_{(\\hat y_i = y_i)}\\hat w_i = \\frac{1}{0.5 + 0.5 + 1 + 1 + 1} \\sum_i 1_{(\\hat y_i = y_i)}\\hat w_i = \\frac{1}{4} (0.5 + 1) = \\frac{3}{8} = 0.375\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is important to look at the confusion matrix of the prediction.\n",
    "\n",
    "**Question:** What is the confusion matrix? What are the conclusions that we can draw from the ```confusion_matrix(y_test, clf4.predict(X_test))```\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "By definition a confusion matrix $C$ is such that  $C_{i,j}$ is equal to the number of observations known to be in group $i$ and predicted to be in group $j$.\n",
    "\n",
    "Here, when can see for example that : \n",
    "\n",
    "* 0 are well identified (all predicted as being 0's)\n",
    "* 3 are sometimes (3 times out of 23) identified as 5\n",
    "* 8 are also sometimes (3 times out of 17) identified as 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 24  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 14  1  1  0  0  0  0  0]\n",
      " [ 0  0  0 18  0  3  0  0  1  1]\n",
      " [ 0  1  0  0 17  0  0  0  0  2]\n",
      " [ 1  0  0  1  0  6  0  1  0  1]\n",
      " [ 1  2  1  0  0  0 20  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 15  0  0]\n",
      " [ 0  2  0  1  0  3  0  0 11  0]\n",
      " [ 0  0  0  0  2  0  0  2  1 21]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, clf4.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2 -- Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data that we have contains images with $10$ classes. Normally, accuracy is a reasonable choice of the loss function to be optimized, but in this problem we *really* do not like when digits from $\\{5, 6, 7, 8, 9\\}$ are predicted to be from $\\{0, 1, 2, 3, 4\\}$.\n",
    "\n",
    "When writing your report on this part, include:\n",
    "   1. description of your loss function\n",
    "   2. description of the pipeline\n",
    "   3. description of the algorithms that you used \n",
    "\n",
    "## First thought\n",
    "\n",
    "**Question:** Propose a loss function that would address our needs. Explain your choice.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "For this problem, our **FIRST IDEA** was to define two sets :\n",
    "\n",
    "1. Class 1 = {0,1,2,3,4} \n",
    "2. Class 0 = {5,6,7,8,9} \n",
    "\n",
    "In order to find a proper loss function, we use the definition of the precision score.\n",
    "In fact, we want to minimize Y_pred in class  when Y_true in class 0 (reduce False Positive rate).\n",
    "\n",
    "In a binary classification task, the terms ‘’positive’’ and ‘’negative’’ refer to the classifier’s prediction, and the terms ‘’true’’ and ‘’false’’ refer to whether that prediction corresponds to the external judgment (sometimes known as the ‘’observation’’). Given these definitions, we can formulate the following table:\n",
    "\n",
    "\n",
    "|  | Actual : Class 1                                                     | Actual : Class 0                                                     |   |   |\n",
    "|--------------------------|-------------------------------------------------------------|-------------------------------------------------------------|---|---|\n",
    "| Predicted : Class 1                  | TP (True Positive) Y_true and Y_pred in Class 1             | FP (False Positive) Y_true in Class 0 and Y_pred in Class 1 |   |   |\n",
    "| Predicted : Class 0                  | FN (False Negative) Y_true in Class 1 and Y_pred in Class 0 | TN (True Negative) Y_true and Y_pred in Class 0             |   |   |\n",
    "\n",
    "\n",
    "\n",
    "In this context, we can define the notions of precision as : $\\text{precision} = \\frac{tp}{tp + fp},$ which is the indicator which is the most interesting to answer to this problem.\n",
    "\n",
    " **=> After training the model, we compare our results with the previous confusion matrix to verify that the bottom right square has evolved well : the sum of the last five lines and the first five columns should be smaller.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define New precision score function with 2 class : Class 1 = {0,1,2,3,4} and Class 0 = {5,6,7,8,9}\n",
    "def custom_precision_score(y_true, y_pred):\n",
    "    #Class 1 = {0,1,2,3,4} and Class 0 = {5,6,7,8,9}\n",
    "    #Calcul TP (True Positive) = y_true and y_pred in class 1\n",
    "    true_positive = np.sum((y_true.astype(int) < 5 ) & (y_pred.astype(int) < 5))\n",
    "    #Calcul FP (False Positive) = y_true in class 0 and y_pred in class 1\n",
    "    false_positive = np.sum((y_true.astype(int) > 4) & (y_pred.astype(int) < 5))\n",
    "    return true_positive / (true_positive + false_positive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Following above examples, make an ML pipeline that uses *your* loss function and finds appropriate classifiers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_svc(model):\n",
    "    #define the scorer\n",
    "    scorer = make_scorer(custom_precision_score, greater_is_better=True)\n",
    "    pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', model)])\n",
    "    parameters = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "    clf = GridSearchCV(pipe, parameters, cv=3, scoring=scorer)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests on different models\n",
    "def evaluation_model(model):\n",
    "    grid=use_svc(model)\n",
    "    print('{} -- Returned hyperparameter: {}'.format(model, grid.best_params_))\n",
    "    print('{} -- Best accuracy in train is: {}'.format(model, grid.best_score_))\n",
    "    print('{} -- Accuracy on test is: {}'.format(model, grid.score(X_test, y_test)))\n",
    "    best_model = grid.best_estimator_\n",
    "    print('{} -- Best Estimator in train is: {}'.format(model, grid.best_estimator_))\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print('{} -- Custom precision score in test is: {}'.format(model, custom_precision_score(y_test, y_pred)))\n",
    "    print('{} -- Confusion matrix: \\n {}'.format(model, confusion_matrix(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=5000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) -- Returned hyperparameter: {'svc__C': 0.125}\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=5000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) -- Best accuracy in train is: 0.9222826688026527\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=5000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) -- Accuracy on test is: 0.9279279279279279\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=5000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) -- Best Estimator in train is: Pipeline(memory=None,\n",
      "         steps=[('scaler', MaxAbsScaler(copy=True)),\n",
      "                ('svc',\n",
      "                 LinearSVC(C=0.125, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=5000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=5000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) -- Custom precision score in test is: 0.9279279279279279\n",
      "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
      "          intercept_scaling=1, loss='squared_hinge', max_iter=5000,\n",
      "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "          verbose=0) -- Confusion matrix: \n",
      " [[22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 23  0  2  0  0  0  0  0  1]\n",
      " [ 1  0 14  1  0  0  0  0  0  0]\n",
      " [ 0  0  1 20  0  0  0  0  1  1]\n",
      " [ 0  1  1  0 17  0  0  0  1  0]\n",
      " [ 1  0  0  1  0  7  0  1  0  0]\n",
      " [ 1  0  0  0  0  1 20  0  1  1]\n",
      " [ 0  0  0  0  1  0  0 14  0  1]\n",
      " [ 0  1  0  1  0  2  1  0 12  0]\n",
      " [ 0  0  0  0  2  0  0  2  1 21]]\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) -- Returned hyperparameter: {'svc__C': 2.0}\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) -- Best accuracy in train is: 0.9379540095272763\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) -- Accuracy on test is: 0.9629629629629629\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) -- Best Estimator in train is: Pipeline(memory=None,\n",
      "         steps=[('scaler', MaxAbsScaler(copy=True)),\n",
      "                ('svc',\n",
      "                 SVC(C=2.0, break_ties=False, cache_size=200, class_weight=None,\n",
      "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
      "                     gamma='scale', kernel='rbf', max_iter=5000,\n",
      "                     probability=False, random_state=None, shrinking=True,\n",
      "                     tol=0.001, verbose=False))],\n",
      "         verbose=False)\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) -- Custom precision score in test is: 0.9629629629629629\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=5000, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False) -- Confusion matrix: \n",
      " [[22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 24  1  1  0  0  0  0  0  0]\n",
      " [ 0  0 16  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 21  0  1  0  0  0  1]\n",
      " [ 0  0  1  0 18  0  0  0  0  1]\n",
      " [ 0  0  0  0  0 10  0  0  0  0]\n",
      " [ 0  1  1  0  0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 16  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 15  0]\n",
      " [ 0  0  0  0  0  0  0  1  1 24]]\n"
     ]
    }
   ],
   "source": [
    "svc_linear = LinearSVC(max_iter=5000)\n",
    "svc = SVC(max_iter=5000)\n",
    "\n",
    "dict_of_models = {'Linear SVC': svc_linear,\n",
    "                  'SVC': svc\n",
    "                  }\n",
    "for name, model in dict_of_models.items():\n",
    "    evaluation_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>\n",
    "Isabelle : Peaufiner la mise en forme des résultats et conclure. Par ailleurs, je te poserai des questions à l'oral durant le point ! \n",
    "</mark>\n",
    "    \n",
    "\n",
    "**=> However, this method does not allow to penalize the error of classification inside the two classes (1 and 0). For example, if I predict a 0 instead of a 1 it is not penalized in the loss function whereas it should be.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Second thought\n",
    "\n",
    "**Question:** Propose a loss function that would address our needs. Explain your choice.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "Our **SECOND IDEA** was to change the loss function in another way to take into account the fact that we must penalize if we predict the wrong number even if the actual or predicted values are both small or large\n",
    "\n",
    "\n",
    "In the usual classification that we made above, we used the following loss \n",
    "$$l_1(y,\\hat{y}) = 1_{\\hat{y} \\ne y}$$\n",
    "\n",
    "Here, we can modify a little bit to show that we do not like if $y \\in H = \\{5, 6, 7, 8, 9\\}$ and $\\hat{y} \\in L = \\{0, 1, 2, 3, 4\\}$. \n",
    "\n",
    "$$\n",
    "l_2(y,\\hat{y}) = 1_{(\\hat{y} \\ne y) \\& [(y \\notin H) \\text{ or } (\\hat{y} \\notin L)]} + \\alpha * 1_{(\\hat{y} \\ne y) \\& (y \\in H) \\& (\\hat{y} \\in L)}\n",
    "$$\n",
    "\n",
    "where $\\alpha > 1$ reflects the aversion that you have when $y \\in H$ and $\\hat{y} \\in L$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# this function returns a vector containing the loss for each pair of (y_true, y_pred)\n",
    "def my_custom_loss_func(y_true,y_pred, alpha):\n",
    "    df = pd.DataFrame({'y_true': [int(s) for s in y_true],'y_pred': [int(s) for s in y_pred]})\n",
    "    df['loss'] = 1* (df['y_true'] != df['y_pred'])\n",
    "    df['loss'] = df['loss'] + (alpha-1)*((df['y_true'] >4) & (df['y_pred'] < 5))\n",
    "    return df['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "Name: loss, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# an example to illustrate it\n",
    "y_true = ['9', '9', '9'] #we have 3 nines in the dataset\n",
    "y_pred = ['9', '8', '1'] \n",
    "#the first one is well-predicted (loss 0),\n",
    "#the second one is bad predicted but still high (loss 1)\n",
    "#the last one is very bad predicted (with a low number) (loss alpha=2)\n",
    "print(my_custom_loss_func(y_true,y_pred, alpha=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to define the scoring parameter to evaluate the predictions on the test set. All scorer objects follow the convention that higher return values are better than lower return values.\n",
    "\n",
    "Previously we saw, two kinds of scorers : \n",
    "\n",
    "* The Accuracy classification score.\n",
    "* The Balanced accuracy classification score. \n",
    "\n",
    "\n",
    "\n",
    "Here, we try to adapte theses scorers to take into account that we really don't like when $y \\in H$ and $\\hat{y} \\in L$. We propose two new scorers : \n",
    "\n",
    "* The Accuracy \"2\" classification score. \n",
    "$$\n",
    "\\texttt{accuracy}_{2}(y, \\hat{y}) = 1- (\\frac{1}{\\alpha * n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} l_2(y,\\hat{y})) = 1- (\\frac{1}{\\alpha * n_\\text{samples}} \\sum_{i=0}^{n_\\text{samples}-1} 1_{(\\hat{y} \\ne y) \\& [(y \\notin H) \\text{ or } (\\hat{y} \\notin L)]} + \\alpha * 1_{(\\hat{y} \\ne y) \\& (y \\in H) \\& (\\hat{y} \\in L)}) \n",
    "$$\n",
    "\n",
    "* The Balanced accuracy \"2\" classification score. \n",
    "\n",
    "$$\n",
    "balanced-accuracy_2(y,\\hat y,w)=1 - (\\frac{1}{\\alpha * \\sum \\hat w_i} \\sum_i l_2(y,\\hat{y}) \\hat w_i)\n",
    "$$\n",
    "\n",
    "with still\n",
    "$$\n",
    "\\hat{w}_i = \\frac{w_i}{\\sum_j{1(y_j = y_i) w_j}}\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both functions evaluate the quality of the prediction.\n",
    "\n",
    "#accuracy_2 function\n",
    "def accuracy_2(y_true,y_pred, alpha):\n",
    "    nsamples = len(y_true)\n",
    "    loss = my_custom_loss_func(y_true,y_pred,alpha)\n",
    "    score = 1-((1/(alpha*nsamples)) * sum(loss))\n",
    "    return score\n",
    "\n",
    "#balanced_accuracy_2 function\n",
    "def balanced_accuracy_2(y_true,y_pred, alpha):\n",
    "    C = confusion_matrix(y_true, y_pred, sample_weight=None)    \n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        wi_hat_par_cat = 1/C.sum(axis=1)\n",
    "    if np.any(np.isinf(wi_hat_par_cat)):\n",
    "        wi_hat_par_cat = wi_hat_par_cat[~np.isinf(wi_hat_par_cat)]    \n",
    "\n",
    "    wi_hat= [None] * len(y_true)\n",
    "    for i in range(len(y_true)):     #np.unique(y_true):\n",
    "        for j in range(len(wi_hat_par_cat)): #np.unique(y_true): \n",
    "            if y_true[i]==np.unique(y_true)[j]: \n",
    "                wi_hat[i]=wi_hat_par_cat[j]\n",
    "    loss = my_custom_loss_func(y_true,y_pred,alpha)\n",
    "    score = 1-((1/(alpha*sum(wi_hat))) * sum(loss*wi_hat))\n",
    "    return(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_2 :  0.5\n",
      "balanced_accuracy_2 :  0.5\n"
     ]
    }
   ],
   "source": [
    "# going back to the previous example to illustrate it\n",
    "y_true = ['9', '9', '9'] \n",
    "y_pred = ['9', '8', '1'] \n",
    "print(\"accuracy_2 : \", accuracy_2(y_true,y_pred,alpha=2))\n",
    "print(\"balanced_accuracy_2 : \", balanced_accuracy_2(y_true,y_pred,alpha=2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Following above examples, make an ML pipeline that uses *your* loss function and finds appropriate classifiers.\n",
    "\n",
    "**Answer:** \n",
    "\n",
    "Now that we have defined the loss and the score functions, let's try to use this score with the 3 different methods (KNN, LinearSVC and LogisticRegression) of machine learning we discovered for this TP and evaluate them. Note that we still want that the sum of the last five lines and the first five columns of the confusion matrix should be smaller than before.\n",
    "\n",
    "**=> Whereas the change of the loss doesn't change the model obtained with the knn method, with the LinearSVC, we obtained different results from the previous models, with a confusion matrix evolving in the good way (smaller sum of the bottom left quarter). See details in the code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which calculates the sum of the last five lines and five first columns of C\n",
    "def sum_unwanted(clf):\n",
    "    C=confusion_matrix(y_test, clf.predict(X_test))\n",
    "    res = sum(C[5][:4])+sum(C[6][:5])+sum(C[7][:6])+sum(C[8][:7])+sum(C[9][:8])\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function which evaluates the model\n",
    "def evaluation_model(clf):\n",
    "    print('Returned hyperparameter: {}'.format(clf.best_params_))\n",
    "    print('Best classification accuracy2 in train is: {}'.format(clf.best_score_))\n",
    "    print('Classification accuracy2 on test is: {}'.format(clf.score(X_test, y_test)))\n",
    "    print('Confusion matrix: \\n', confusion_matrix(y_test, clf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_knn(alpha, balanced=False):\n",
    "    if not balanced:\n",
    "        scorer = make_scorer(accuracy_2, alpha=alpha)\n",
    "    else:\n",
    "        scorer = make_scorer(balanced_accuracy_2, alpha=alpha)   \n",
    "    knn = KNeighborsClassifier() # defining classifier\n",
    "    parameters = {'n_neighbors': [1, 2, 3, 4, 5]} # defining parameter space\n",
    "    clf = GridSearchCV(knn, parameters, cv=3, scoring=scorer)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $\\alpha = 1$, we logically have the same results as the beginning of this TP: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'n_neighbors': 1}\n",
      "Best classification accuracy2 in train is: 0.891497944721333\n",
      "Classification accuracy2 on test is: 0.875\n",
      "Confusion matrix: \n",
      " [[21  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 26  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  2  0  0  0  0]\n",
      " [ 0  0  0 19  0  2  0  0  1  1]\n",
      " [ 0  1  0  0 17  0  0  0  0  2]\n",
      " [ 0  0  0  0  1  7  1  0  1  0]\n",
      " [ 0  0  0  0  0  1 23  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 15  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 14  1]\n",
      " [ 1  1  0  0  2  0  0  3  0 19]]\n"
     ]
    }
   ],
   "source": [
    "clf7_alpha1 = use_knn(alpha=1, balanced=False)\n",
    "evaluation_model(clf7_alpha1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try to increase the value of $\\alpha$ that is to say to penalize more when $y \\in H$ and $\\hat{y} \\in L$. let's try $\\alpha=10$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'n_neighbors': 1}\n",
      "Best classification accuracy2 in train is: 0.9590000045022534\n",
      "Classification accuracy2 on test is: 0.9515\n",
      "Confusion matrix: \n",
      " [[21  0  0  0  0  0  1  0  0  0]\n",
      " [ 0 26  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 14  0  0  2  0  0  0  0]\n",
      " [ 0  0  0 19  0  2  0  0  1  1]\n",
      " [ 0  1  0  0 17  0  0  0  0  2]\n",
      " [ 0  0  0  0  1  7  1  0  1  0]\n",
      " [ 0  0  0  0  0  1 23  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 15  0  0]\n",
      " [ 0  1  0  1  0  0  0  0 14  1]\n",
      " [ 1  1  0  0  2  0  0  3  0 19]]\n"
     ]
    }
   ],
   "source": [
    "clf7_alpha10 = use_knn(alpha=10, balanced=False)\n",
    "evaluation_model(clf7_alpha10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is better than the previous one but, be careful, we cannot compare the two accuracies because they are not using the same formula because it depends on the value of $\\alpha$.\n",
    "\n",
    "Unfortunately, the confusion matrix does not change because the best model remains the same (`n_neighbours = 1`) and do not decrease. However, this is totally normal because the parameter `n_neighbours = 1` already corresponds to the minimum :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameter  1 the sum of the left-bottom quarter of C is  10\n",
      "With parameter  2 the sum of the left-bottom quarter of C is  17\n",
      "With parameter  3 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  4 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  5 the sum of the left-bottom quarter of C is  13\n"
     ]
    }
   ],
   "source": [
    "for n in [1, 2, 3, 4, 5]:\n",
    "    knn = KNeighborsClassifier(n_neighbors = n);\n",
    "    knn.fit(X_train, y_train)\n",
    "    print('With parameter ',n, 'the sum of the left-bottom quarter of C is ', sum_unwanted(knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_svc(alpha, balanced=False,linear=True):\n",
    "    #define the model\n",
    "    if linear:\n",
    "         model = LinearSVC(max_iter=5000)\n",
    "    else:\n",
    "         model =  SVC(max_iter=5000)\n",
    "    #define the scorer\n",
    "    if not balanced:\n",
    "        scorer = make_scorer(accuracy_2, alpha=alpha)\n",
    "    else:\n",
    "        scorer = make_scorer(balanced_accuracy_2, alpha=alpha)  \n",
    "        \n",
    "    pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', model)])\n",
    "    parameters = {'svc__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "    clf = GridSearchCV(pipe, parameters, cv=3, scoring=scorer)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the LinearSVC model with a balanced_accuracy function. With $\\alpha = 1$ the results are obviously the same as previously that is to say : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'svc__C': 0.015625}\n",
      "Best classification accuracy2 in train is: 0.8612334093654243\n",
      "Classification accuracy2 on test is: 0.8256270083284148\n",
      "Confusion matrix: \n",
      " [[22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 24  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 14  1  1  0  0  0  0  0]\n",
      " [ 0  0  0 18  0  3  0  0  1  1]\n",
      " [ 0  1  0  0 17  0  0  0  0  2]\n",
      " [ 1  0  0  1  0  6  0  1  0  1]\n",
      " [ 1  2  1  0  0  0 20  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 15  0  0]\n",
      " [ 0  2  0  1  0  3  0  0 11  0]\n",
      " [ 0  0  0  0  2  0  0  2  1 21]]\n"
     ]
    }
   ],
   "source": [
    "clf8_alpha1 = use_svc(alpha=1, balanced=True,linear=True)\n",
    "evaluation_model(clf8_alpha1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that, here, the parameter of the initial model `C=0.015625`is not the one which minimizes the sum of the bottom left quarter of the confusion matrix. The minimum is $13$ for `C=0.125`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameter  0.00390625 the sum of the left-bottom quarter of C is  18\n",
      "With parameter  0.0078125 the sum of the left-bottom quarter of C is  17\n",
      "With parameter  0.015625 the sum of the left-bottom quarter of C is  17\n",
      "With parameter  0.03125 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  0.0625 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  0.125 the sum of the left-bottom quarter of C is  13\n",
      "With parameter  0.25 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  0.5 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  1.0 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  2.0 the sum of the left-bottom quarter of C is  16\n",
      "With parameter  4.0 the sum of the left-bottom quarter of C is  16\n",
      "With parameter  8.0 the sum of the left-bottom quarter of C is  16\n",
      "With parameter  16.0 the sum of the left-bottom quarter of C is  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kim Antunez\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameter  32.0 the sum of the left-bottom quarter of C is  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kim Antunez\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameter  64.0 the sum of the left-bottom quarter of C is  16\n",
      "With parameter  128.0 the sum of the left-bottom quarter of C is  16\n",
      "With parameter  256.0 the sum of the left-bottom quarter of C is  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kim Antunez\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for c in np.logspace(-8, 8, 17, base=2):\n",
    "    model = LinearSVC(max_iter=5000,C=c)\n",
    "    pipe = Pipeline([('scaler', MaxAbsScaler()), ('svc', model)])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print('With parameter ',c, 'the sum of the left-bottom quarter of C is ', sum_unwanted(pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With $\\alpha = 1000$, we get the expected result because the best model is now the one with `C=0.125` and the confusion matrix did changed in the good way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'svc__C': 0.015625}\n",
      "Best classification accuracy2 in train is: 0.9484628402030914\n",
      "Classification accuracy2 on test is: 0.9211322709685881\n",
      "Confusion matrix: \n",
      " [[22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 24  0  0  0  0  0  0  2  0]\n",
      " [ 0  0 14  1  1  0  0  0  0  0]\n",
      " [ 0  0  0 18  0  3  0  0  1  1]\n",
      " [ 0  1  0  0 17  0  0  0  0  2]\n",
      " [ 1  0  0  1  0  6  0  1  0  1]\n",
      " [ 1  2  1  0  0  0 20  0  0  0]\n",
      " [ 0  0  0  0  1  0  0 15  0  0]\n",
      " [ 0  2  0  1  0  3  0  0 11  0]\n",
      " [ 0  0  0  0  2  0  0  2  1 21]]\n"
     ]
    }
   ],
   "source": [
    "clf8_alpha1000 = use_svc(alpha=1000, balanced=True,linear=True)\n",
    "evaluation_model(clf8_alpha10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_logistic(alpha, balanced=False):\n",
    "    #define the scorer\n",
    "    if not balanced:\n",
    "        scorer = make_scorer(accuracy_2, alpha=alpha)\n",
    "    else:\n",
    "        scorer = make_scorer(balanced_accuracy_2, alpha=alpha)  \n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(max_iter=5000))])\n",
    "    parameters = {'logreg__C': np.logspace(-8, 8, 17, base=2)} # defining parameter space\n",
    "    clf = GridSearchCV(pipe, parameters, cv=3, scoring=scorer)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of the LogisticRegression model with a accuracy function. First, with $\\alpha = 1$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned hyperparameter: {'logreg__C': 0.0078125}\n",
      "Best classification accuracy2 in train is: 0.8692423758419983\n",
      "Classification accuracy2 on test is: 0.8337791822414583\n",
      "Confusion matrix: \n",
      " [[22  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  3  0  0  0  0  2  0]\n",
      " [ 0  0 13  1  1  0  1  0  0  0]\n",
      " [ 0  0  1 17  0  3  0  0  1  1]\n",
      " [ 0  1  0  0 18  0  0  0  0  1]\n",
      " [ 1  0  0  0  0  8  0  1  0  0]\n",
      " [ 1  1  1  0  0  0 20  0  1  0]\n",
      " [ 0  0  0  0  1  0  0 14  0  1]\n",
      " [ 0  2  0  1  0  3  0  0 11  0]\n",
      " [ 0  0  0  0  0  0  0  2  0 24]]\n"
     ]
    }
   ],
   "source": [
    "clf9_alpha1 = use_logistic(alpha=1, balanced=True)\n",
    "evaluation_model(clf9_alpha1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that, here, the parameter of the initial model `0.0078125` already the one which minimizes the sum of the bottom left quarter of the confusion matrix. The minimum is also the same ($13$) for `C=0.00390625`  and `C=0.25`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With parameter  0.00390625 the sum of the left-bottom quarter of C is  13\n",
      "With parameter  0.0078125 the sum of the left-bottom quarter of C is  13\n",
      "With parameter  0.015625 the sum of the left-bottom quarter of C is  16\n",
      "With parameter  0.03125 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  0.0625 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  0.125 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  0.25 the sum of the left-bottom quarter of C is  13\n",
      "With parameter  0.5 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  1.0 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  2.0 the sum of the left-bottom quarter of C is  14\n",
      "With parameter  4.0 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  8.0 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  16.0 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  32.0 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  64.0 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  128.0 the sum of the left-bottom quarter of C is  15\n",
      "With parameter  256.0 the sum of the left-bottom quarter of C is  15\n"
     ]
    }
   ],
   "source": [
    "for c in np.logspace(-8, 8, 17, base=2):\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('logreg', LogisticRegression(max_iter=5000,C = c))])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    print('With parameter ',c, 'the sum of the left-bottom quarter of C is ', sum_unwanted(pipe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convertir en Markdown pour le rapport latex : copier coller dans le terminal Jupyter. \n",
    "#cd \"C:\\Users\\Kim Antunez\\Desktop\\3A\\ML\\DM_ML\\TP1\"\n",
    "#jupyter nbconvert --to markdown TP1_KA_IB.ipynb"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
